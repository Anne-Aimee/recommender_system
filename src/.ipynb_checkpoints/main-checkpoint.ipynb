{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../utilities/')\n",
    "from helpers import *\n",
    "from plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID indicates both the user and the item : user are identified as \"r\"+\"index\" from 1 to 10000, and items as \"c\"+ \"index\" from 1 to 1000. The format of the ID are consequently : r index(user) _ c index(item).\n",
    "The ratings are given as integers from 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute them into a matrix with items as row and users as columns. All of the missing ratings are set as 0 and should be predicted to have a valid rating format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = '../Datasets/data_train.csv'\n",
    "ratings = load_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 3, min # of users per item = 8.\n"
     ]
    }
   ],
   "source": [
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing - Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # split the data and return train and test data.\n",
    "    # we only consider users and movies that have more than 10 ratings\n",
    "\n",
    "    ind_test = np.random.choice(valid_ratings.nnz, int(valid_ratings.nnz*p_test), replace=False)\n",
    "    ind_train = np.delete(np.arange(valid_ratings.nnz),ind_test)\n",
    "    \n",
    "    valid_ratings_coo = valid_ratings.tocoo()\n",
    "    data = valid_ratings_coo.data\n",
    "    row = valid_ratings_coo.row\n",
    "    col = valid_ratings_coo.col\n",
    "    \n",
    "    test = sp.coo_matrix((data[ind_test], (row[ind_test], col[ind_test])), shape=valid_ratings.get_shape())\n",
    "    train = sp.coo_matrix((data[ind_train], (row[ind_train], col[ind_train])), shape=valid_ratings.get_shape()) \n",
    "    \n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1059186\n",
      "Total number of nonzero elements in test data:117687\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1167843007553209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"  \n",
    "    \n",
    "    return sqrt(calculate_mse(test.data,np.mean(train.data))/(test.nnz))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0943344686705307"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    #Sum over nth user\n",
    "    sum_ratings_movie = np.squeeze(np.asarray(train.sum(0)))    # sum of the nonzero elements, for each row\n",
    "    count_ratings_movie = np.diff(train.tocsc().indptr)         # count of the nonzero elements, for each row\n",
    "    mean_rating_movie = sum_ratings_movie/count_ratings_movie\n",
    "    return sqrt(calculate_mse(test.data,mean_rating_movie[test.col])/(test.nnz))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0292360165304137"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    #Sum over dth movie\n",
    "    sum_ratings_user = np.squeeze(np.asarray(train.sum(1)))    # sum of the nonzero elements, for each row\n",
    "    count_ratings_user = np.diff(train.tocsr().indptr)         # count of the nonzero elements, for each row\n",
    "    mean_rating_user = sum_ratings_user/count_ratings_user\n",
    "\n",
    "    return sqrt(calculate_mse(test.data,mean_rating_user[test.row])/(test.nnz))\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item/user means as prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0002486362462182"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def baseline_item_user(train, test):\n",
    "    \"\"\"baseline method: find best parameters for the model y_dn = w_0 + w_item[d] + w_user[n] (D+N+1) parameters\n",
    "       and make a prediction.\"\"\"\n",
    "    \n",
    "    global_mean = np.mean(train.data)\n",
    "    \n",
    "    #Sum over nth user\n",
    "    sum_ratings_movie = np.squeeze(np.asarray(train.sum(0)))    # sum of the nonzero elements, for each row\n",
    "    count_ratings_movie = np.diff(train.tocsc().indptr)         # count of the nonzero elements, for each row\n",
    "    \n",
    "    #Sum over dth movie\n",
    "    sum_ratings_user = np.squeeze(np.asarray(train.sum(1)))    # sum of the nonzero elements, for each col\n",
    "    count_ratings_user = np.diff(train.tocsr().indptr)         # count of the nonzero elements, for each col\n",
    "    \n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    # Constructing linear system defining the model's optimal parameters in form of a matrix\n",
    "    \n",
    "    # Matrix of the same shape as ratings, 1 if rating present, 0 otherwise\n",
    "    mask_train = sp.coo_matrix((np.ones(train.nnz), (train.row, train.col)), shape=train.shape) \n",
    "    \n",
    "    A = sp.hstack((sp.diags(count_ratings_user), mask_train))\n",
    "    A = sp.vstack((A, sp.hstack((mask_train.T, sp.diags(count_ratings_movie)))))\n",
    "    A = sp.hstack((A, sp.coo_matrix(np.concatenate((count_ratings_movie,count_ratings_user))).T))\n",
    "    A = sp.vstack((A, sp.coo_matrix(np.ones(num_items+num_users+1))))\n",
    "    \n",
    "    b = np.append(np.concatenate((sum_ratings_user, sum_ratings_movie)),global_mean)\n",
    "    \n",
    "    # Solving the system\n",
    "    x = spsolve(A.tocsc(),b)\n",
    "    \n",
    "    # Extracting the parameters w_0, w_item[d] and w_user[n] \n",
    "    w_item, w_user, w_0 = np.split(x,np.array([num_items,num_items+num_users]))\n",
    "    \n",
    "    plt.scatter(w_item[test.row] + w_user[test.col] + w_0, test.data)\n",
    "    \n",
    "    return sqrt(calculate_mse(test.data, w_item[test.row] + w_user[test.col] + w_0)/(test.nnz))\n",
    "    \n",
    "baseline_item_user(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "    \n",
    "    # returns initialized with random values :\n",
    "    #     user_features: shape = num_features, num_user\n",
    "    #     item_features: shape = num_features, num_item\n",
    "\n",
    "    \n",
    "    max_initial_value = 2*sqrt(np.mean(train.data)/num_features)\n",
    "    \n",
    "    user_features = max_initial_value*np.random.rand(num_features, train.shape[1])\n",
    "    item_features = max_initial_value*np.random.rand(num_features, train.shape[0])\n",
    "\n",
    "    \n",
    "    return user_features,item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "\n",
    "    # calculate rmse (we only consider nonzero entries.)\n",
    "    approx_data_matrix = np.dot(item_features.T,user_features)\n",
    "    return sqrt(calculate_mse(data,approx_data_matrix[nz])/(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix factorization SGD basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0679046970987307, RMSE on testing set: 1.1028435045814358.\n",
      "iter: 1, RMSE on training set: 1.039899090892994, RMSE on testing set: 1.099446723942877.\n",
      "iter: 2, RMSE on training set: 1.0125700340876733, RMSE on testing set: 1.0992430579902652.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1b1316646dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE on test data: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-1b1316646dde>\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# update matrix factorization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.05\n",
    "    num_features = 25   # K in the lecture notes\n",
    "    num_epochs = 30     # number of full iterations through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col, train.data))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    rmse_tr = compute_error(train.data, user_features, item_features, train.nonzero())\n",
    "    rmse_te = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "    print(\"initial RMSE on training set: {}, RMSE on testing set: {}.\".format(rmse_tr,rmse_te))\n",
    "    \n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n, x_dn in nz_train:\n",
    "        # update matrix factorization.     \n",
    "\n",
    "            item_features[:,d] += gamma*(x_dn - np.inner(item_features[:,d],user_features[:,n]))*user_features[:,n]\n",
    "            user_features[:,n] += gamma*(x_dn - np.inner(item_features[:,d],user_features[:,n]))*item_features[:,d]\n",
    "        \n",
    "        rmse_tr = compute_error(train.data, user_features, item_features, train.nonzero())\n",
    "        rmse_te = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "        print(\"iter: {}, RMSE on training set: {}, RMSE on testing set: {}.\".format(it, rmse_tr,rmse_te))\n",
    "        \n",
    "        errors.append(rmse_te)\n",
    "\n",
    "    # evaluate the test error.\n",
    "    rmse = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "\n",
    "matrix_factorization_SGD(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix factorization SGD regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization_SGD_regularized(train, test, num_features, lambda_user, lambda_item, gamma, gamma_dec_step_size, num_epochs, seed, stop_criterion):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices  \n",
    "    nz_train = list(zip(train.row, train.col, train.data))\n",
    "    \n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    rmse_tr = [compute_error(train.data, user_features, item_features, train.nonzero())]\n",
    "    rmse_te = [compute_error(test.data, user_features, item_features, test.nonzero())]\n",
    "    print(\"initial RMSE on training set: {}, RMSE on testing set: {}.\".format(rmse_tr[0],rmse_te[0]))\n",
    "    \n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= gamma_dec_step_size\n",
    "        \n",
    "        for d, n, x_dn in nz_train:\n",
    "        # update matrix factorization.\n",
    "\n",
    "            item_features[:,d] += gamma*((x_dn - np.inner(item_features[:,d],user_features[:,n]))*user_features[:,n]-lambda_item*item_features[:,d])\n",
    "            user_features[:,n] += gamma*((x_dn - np.inner(item_features[:,d],user_features[:,n]))*item_features[:,d]-lambda_user*user_features[:,n])\n",
    "        \n",
    "        rmse_tr.append(compute_error(train.data, user_features, item_features, train.nonzero()))\n",
    "        rmse_te.append(compute_error(test.data, user_features, item_features, test.nonzero()))\n",
    "        print(\"iter: {}, RMSE on training set: {}, RMSE on testing set: {}.\".format(it, rmse_tr[-1],rmse_te[-1]))\n",
    "        \n",
    "        if np.isclose(rmse_tr[-1],rmse_tr[-2],stop_criterion) or rmse_tr[-1] > rmse_tr[0]:\n",
    "            break\n",
    "            \n",
    "    # evaluate the test error.\n",
    "    min_rmse_te = min(rmse_te)\n",
    "    print(\"RMSE on test data: {}.\".format(min_rmse_te))\n",
    "    \n",
    "    return min_rmse_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters \n",
    "num_features = 40   # K in the lecture notes\n",
    "\n",
    "lambda_user = 0.08\n",
    "lambda_item = 0.08\n",
    "    \n",
    "gamma = 0.05\n",
    "gamma_dec_step_size = 1.2\n",
    "num_epochs = 30     # number of full passes through the train set\n",
    "stop_criterion = 1e-4\n",
    "    \n",
    "seed = 988\n",
    "\n",
    "matrix_factorization_SGD_regularized(train, test, num_features, lambda_user, lambda_item, gamma, gamma_dec_step_size, num_epochs, seed, stop_criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_simple_heatmap(data, title, xlabel, xticklabels, ylabel, yticklabels):\n",
    "\n",
    "    f,a = plt.subplots()\n",
    "    a.set_xlabel(xlabel)\n",
    "    a.set_xticks(range(len(xticklabels)))\n",
    "    a.set_xticklabels(xticklabels)\n",
    "    a.set_ylabel(ylabel)\n",
    "    a.set_yticks(range(len(yticklabels)))\n",
    "    a.set_yticklabels(yticklabels)\n",
    "    a.set_title(title)\n",
    "    heatmap_corr = a.imshow(data)\n",
    "    f.colorbar(heatmap_corr, ax=a)\n",
    "    \n",
    "data = np.random.rand(5,7)\n",
    "plot_simple_heatmap(data, \"title\", \"xlabel\",np.arange(7), \"ylabel\",np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_simple_heatmaps(data_1, data_2, fig_title, subtitle_1, subtitle_2, xlabel_shared, ylabel_shared):\n",
    "\n",
    "    f,a = plt.subplots(2,1)\n",
    "    \n",
    "    a[0].set_xlabel(xlabel_shared)\n",
    "    a[0].set_ylabel(ylabel_shared)\n",
    "    a[0].set_title(subtitle_1)\n",
    "    heatmap_0 = a[0].imshow(data_1)\n",
    "\n",
    "    a[1].set_xlabel(xlabel_shared)\n",
    "    a[1].set_ylabel(ylabel_shared)\n",
    "    a[1].set_title(subtitle_2)\n",
    "    heatmap_1 = a[1].imshow(data_2)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    f.colorbar(heatmap_0,ax=a[0])\n",
    "    f.colorbar(heatmap_1,ax=a[1])\n",
    "    \n",
    "    f.suptitle(fig_title)\n",
    "    \n",
    "data_1 = np.random.rand(200,300)\n",
    "data_2 = np.random.rand(200,300)\n",
    "plot_simple_heatmaps(data_1, data_2, 'fig_title', 'subtitle_1', 'subtitle_2', 'xlabel_shared', 'ylabel_shared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best initial gamma and the best decrement step size to compare SGD with ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed (1/2) = 988\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0043474025543135, RMSE on testing set: 1.0206585722434725.\n",
      "iter: 1, RMSE on training set: 0.9986596275987056, RMSE on testing set: 1.0162054617478655.\n",
      "iter: 2, RMSE on training set: 0.9971090060941443, RMSE on testing set: 1.0155509804238534.\n",
      "iter: 3, RMSE on training set: 0.9953685258367746, RMSE on testing set: 1.013729521835026.\n",
      "iter: 4, RMSE on training set: 0.9939093956696281, RMSE on testing set: 1.0124641307975963.\n",
      "iter: 5, RMSE on training set: 0.9927732459514989, RMSE on testing set: 1.0120238078044104.\n",
      "iter: 6, RMSE on training set: 0.9908446237976789, RMSE on testing set: 1.010601439225823.\n",
      "iter: 7, RMSE on training set: 0.9907652944194636, RMSE on testing set: 1.0103972623167314.\n",
      "RMSE on test data: 1.0103972623167314.\n",
      "seed (1/2) = 988\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0039720282248477, RMSE on testing set: 1.0201947286863535.\n",
      "iter: 1, RMSE on training set: 0.9977011086472871, RMSE on testing set: 1.015226224988058.\n",
      "iter: 2, RMSE on training set: 0.9956610373832347, RMSE on testing set: 1.0140070672832722.\n",
      "iter: 3, RMSE on training set: 0.993711648513969, RMSE on testing set: 1.0120307206500856.\n",
      "iter: 4, RMSE on training set: 0.9921390832365102, RMSE on testing set: 1.010581500869001.\n",
      "iter: 5, RMSE on training set: 0.9909589482680013, RMSE on testing set: 1.0100454343424266.\n",
      "iter: 6, RMSE on training set: 0.9892613675242704, RMSE on testing set: 1.0086565994321428.\n",
      "iter: 7, RMSE on training set: 0.9890372600337114, RMSE on testing set: 1.0082711552240078.\n",
      "iter: 8, RMSE on training set: 0.987679337604226, RMSE on testing set: 1.0069412834402314.\n",
      "iter: 9, RMSE on training set: 0.9873755566924375, RMSE on testing set: 1.0066462712899298.\n",
      "iter: 10, RMSE on training set: 0.9871847997360357, RMSE on testing set: 1.0067175925602112.\n",
      "iter: 11, RMSE on training set: 0.9862223896412423, RMSE on testing set: 1.0062063064819602.\n",
      "iter: 12, RMSE on training set: 0.9861100646602564, RMSE on testing set: 1.0059699026684803.\n",
      "iter: 13, RMSE on training set: 0.9855140464093108, RMSE on testing set: 1.005473590903285.\n",
      "iter: 14, RMSE on training set: 0.9853347716300427, RMSE on testing set: 1.0054796901590939.\n",
      "iter: 15, RMSE on training set: 0.9846959342771573, RMSE on testing set: 1.0049944802476478.\n",
      "iter: 16, RMSE on training set: 0.9848120432273084, RMSE on testing set: 1.0050397818334582.\n",
      "iter: 17, RMSE on training set: 0.984412176122149, RMSE on testing set: 1.004772688141244.\n",
      "iter: 18, RMSE on training set: 0.9843918371196145, RMSE on testing set: 1.004786882808749.\n",
      "RMSE on test data: 1.004772688141244.\n",
      "seed (1/2) = 988\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0036688934172835, RMSE on testing set: 1.0198015734687849.\n",
      "iter: 1, RMSE on training set: 0.996912945871579, RMSE on testing set: 1.0144072285350976.\n",
      "iter: 2, RMSE on training set: 0.9945184787425805, RMSE on testing set: 1.0127770630000368.\n",
      "iter: 3, RMSE on training set: 0.9924805178538911, RMSE on testing set: 1.0107542505427818.\n",
      "iter: 4, RMSE on training set: 0.9908900047504438, RMSE on testing set: 1.0092270274038981.\n",
      "iter: 5, RMSE on training set: 0.9897753135069417, RMSE on testing set: 1.0086940954483379.\n",
      "iter: 6, RMSE on training set: 0.9883041128392225, RMSE on testing set: 1.007405753152302.\n",
      "iter: 7, RMSE on training set: 0.9880748566432696, RMSE on testing set: 1.0070388560004202.\n",
      "iter: 8, RMSE on training set: 0.9871043111126749, RMSE on testing set: 1.0061364037298983.\n",
      "iter: 9, RMSE on training set: 0.9869685433489782, RMSE on testing set: 1.0059782681900504.\n",
      "iter: 10, RMSE on training set: 0.9868318143854568, RMSE on testing set: 1.0059990381370498.\n",
      "iter: 11, RMSE on training set: 0.9862064334580716, RMSE on testing set: 1.0056401002119815.\n",
      "iter: 12, RMSE on training set: 0.9861862657739277, RMSE on testing set: 1.005528573237128.\n",
      "RMSE on test data: 1.005528573237128.\n",
      "seed (1/2) = 988\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0034301816825701, RMSE on testing set: 1.0194716132130655.\n",
      "iter: 1, RMSE on training set: 0.9962689717687122, RMSE on testing set: 1.0137234920962532.\n",
      "iter: 2, RMSE on training set: 0.9936213733627123, RMSE on testing set: 1.0117982840181357.\n",
      "iter: 3, RMSE on training set: 0.9915762635645008, RMSE on testing set: 1.009800312675132.\n",
      "iter: 4, RMSE on training set: 0.9900159812602414, RMSE on testing set: 1.0082571231200799.\n",
      "iter: 5, RMSE on training set: 0.9890172434052987, RMSE on testing set: 1.0077677614607659.\n",
      "iter: 6, RMSE on training set: 0.987758595887263, RMSE on testing set: 1.0066245456537957.\n",
      "iter: 7, RMSE on training set: 0.9875782372394513, RMSE on testing set: 1.006344321254438.\n",
      "iter: 8, RMSE on training set: 0.9868758844241057, RMSE on testing set: 1.005736690598965.\n",
      "iter: 9, RMSE on training set: 0.9868141190897539, RMSE on testing set: 1.0056261665916586.\n",
      "RMSE on test data: 1.0056261665916586.\n",
      "seed (1/2) = 988\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0032492220870004, RMSE on testing set: 1.0191984582900755.\n",
      "iter: 1, RMSE on training set: 0.9957477743569937, RMSE on testing set: 1.0131547028573786.\n",
      "iter: 2, RMSE on training set: 0.9929228538589168, RMSE on testing set: 1.0110214422173018.\n",
      "iter: 3, RMSE on training set: 0.9909226729780333, RMSE on testing set: 1.009091997494224.\n",
      "iter: 4, RMSE on training set: 0.9894118520661767, RMSE on testing set: 1.0075656152526766.\n",
      "iter: 5, RMSE on training set: 0.9885442440713536, RMSE on testing set: 1.0071295719765532.\n",
      "iter: 6, RMSE on training set: 0.9874792888101447, RMSE on testing set: 1.0061536103342725.\n",
      "iter: 7, RMSE on training set: 0.9873590611962502, RMSE on testing set: 1.005965108309753.\n",
      "iter: 8, RMSE on training set: 0.9868344412043897, RMSE on testing set: 1.0055419614886218.\n",
      "iter: 9, RMSE on training set: 0.9867978959385844, RMSE on testing set: 1.0054445524734474.\n",
      "RMSE on test data: 1.0054445524734474.\n",
      "seed (1/2) = 988\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0147301289446646, RMSE on testing set: 1.0317096292743455.\n",
      "iter: 1, RMSE on training set: 1.0086341047417493, RMSE on testing set: 1.0262404119230741.\n",
      "iter: 2, RMSE on training set: 1.0067551249665647, RMSE on testing set: 1.0260303085693674.\n",
      "iter: 3, RMSE on training set: 1.0033794485641918, RMSE on testing set: 1.0224040059482011.\n",
      "iter: 4, RMSE on training set: 1.0004463098930652, RMSE on testing set: 1.020053033952434.\n",
      "iter: 5, RMSE on training set: 0.9979959632530987, RMSE on testing set: 1.0187066371184226.\n",
      "iter: 6, RMSE on training set: 0.9938355958030244, RMSE on testing set: 1.0159153993368137.\n",
      "iter: 7, RMSE on training set: 0.9929612900794608, RMSE on testing set: 1.0156026247671948.\n",
      "iter: 8, RMSE on training set: 0.9887257744062456, RMSE on testing set: 1.0118718350528195.\n",
      "iter: 9, RMSE on training set: 0.9860238483628689, RMSE on testing set: 1.0096245619514153.\n",
      "iter: 10, RMSE on training set: 0.9841622236441164, RMSE on testing set: 1.0092425901867776.\n",
      "iter: 11, RMSE on training set: 0.9807165823506192, RMSE on testing set: 1.0073490454627014.\n",
      "iter: 12, RMSE on training set: 0.9786377089093301, RMSE on testing set: 1.0058573156224448.\n",
      "iter: 13, RMSE on training set: 0.9766990347629201, RMSE on testing set: 1.0046824479191234.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 14, RMSE on training set: 0.9748374219866324, RMSE on testing set: 1.0040275377770467.\n",
      "iter: 15, RMSE on training set: 0.9727227150758277, RMSE on testing set: 1.002731740554432.\n",
      "iter: 16, RMSE on training set: 0.9713469186103728, RMSE on testing set: 1.0017856399812364.\n",
      "iter: 17, RMSE on training set: 0.9694652460885098, RMSE on testing set: 1.0008632633162697.\n",
      "iter: 18, RMSE on training set: 0.9680212591443036, RMSE on testing set: 1.0001403552916597.\n",
      "iter: 19, RMSE on training set: 0.9669184196611782, RMSE on testing set: 0.9993120620927223.\n",
      "iter: 20, RMSE on training set: 0.9657591731198611, RMSE on testing set: 0.9992464819104578.\n",
      "iter: 21, RMSE on training set: 0.9647406890459178, RMSE on testing set: 0.9984882199701653.\n",
      "iter: 22, RMSE on training set: 0.9638722430216375, RMSE on testing set: 0.9978022252551422.\n",
      "iter: 23, RMSE on training set: 0.9632731484481675, RMSE on testing set: 0.9978743029561679.\n",
      "iter: 24, RMSE on training set: 0.9626298631730632, RMSE on testing set: 0.9976256307871536.\n",
      "iter: 25, RMSE on training set: 0.96212614812371, RMSE on testing set: 0.9974476382934878.\n",
      "iter: 26, RMSE on training set: 0.9612007272057332, RMSE on testing set: 0.9967049963043809.\n",
      "iter: 27, RMSE on training set: 0.9607902506113125, RMSE on testing set: 0.9965896026444012.\n",
      "iter: 28, RMSE on training set: 0.960061766889378, RMSE on testing set: 0.9962476764945295.\n",
      "iter: 29, RMSE on training set: 0.9599655801616384, RMSE on testing set: 0.9963443094104241.\n",
      "RMSE on test data: 0.9962476764945295.\n",
      "seed (1/2) = 988\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0135419485724801, RMSE on testing set: 1.0304981423716677.\n",
      "iter: 1, RMSE on training set: 1.0065031195305587, RMSE on testing set: 1.024150267003194.\n",
      "iter: 2, RMSE on training set: 1.0037662611459945, RMSE on testing set: 1.0228899958987223.\n",
      "iter: 3, RMSE on training set: 1.0001052710415654, RMSE on testing set: 1.0190243242481953.\n",
      "iter: 4, RMSE on training set: 0.9970589408758054, RMSE on testing set: 1.0164430068652173.\n",
      "iter: 5, RMSE on training set: 0.9946108632018335, RMSE on testing set: 1.01492249264483.\n",
      "iter: 6, RMSE on training set: 0.991209851702138, RMSE on testing set: 1.0124378421866285.\n",
      "iter: 7, RMSE on training set: 0.9903621161145248, RMSE on testing set: 1.0116971858305022.\n",
      "iter: 8, RMSE on training set: 0.9873487744012839, RMSE on testing set: 1.0088771932832619.\n",
      "iter: 9, RMSE on training set: 0.9858996527201345, RMSE on testing set: 1.0076189459977702.\n",
      "iter: 10, RMSE on training set: 0.9849667981278428, RMSE on testing set: 1.0074356156324318.\n",
      "iter: 11, RMSE on training set: 0.9829071737912886, RMSE on testing set: 1.0062635187260789.\n",
      "iter: 12, RMSE on training set: 0.9821151339276292, RMSE on testing set: 1.0055335896239703.\n",
      "iter: 13, RMSE on training set: 0.9809780613232197, RMSE on testing set: 1.0047696256966676.\n",
      "iter: 14, RMSE on training set: 0.9802682959803151, RMSE on testing set: 1.0045438854683941.\n",
      "iter: 15, RMSE on training set: 0.9790417164578, RMSE on testing set: 1.0036416727557644.\n",
      "iter: 16, RMSE on training set: 0.9787661336669592, RMSE on testing set: 1.003408739267913.\n",
      "iter: 17, RMSE on training set: 0.9778742927783717, RMSE on testing set: 1.002927033035049.\n",
      "iter: 18, RMSE on training set: 0.977479966731605, RMSE on testing set: 1.0026771770981526.\n",
      "iter: 19, RMSE on training set: 0.9771700174500518, RMSE on testing set: 1.0024953350258923.\n",
      "iter: 20, RMSE on training set: 0.9767633451069542, RMSE on testing set: 1.0023901424437514.\n",
      "iter: 21, RMSE on training set: 0.9763955002199599, RMSE on testing set: 1.002032104898178.\n",
      "iter: 22, RMSE on training set: 0.9760651300784225, RMSE on testing set: 1.001830746889139.\n",
      "iter: 23, RMSE on training set: 0.9759432679977852, RMSE on testing set: 1.0018607305370404.\n",
      "iter: 24, RMSE on training set: 0.9757337140227743, RMSE on testing set: 1.001702106118218.\n",
      "iter: 25, RMSE on training set: 0.9756595911179463, RMSE on testing set: 1.0016921673108135.\n",
      "RMSE on test data: 1.0016921673108135.\n",
      "seed (1/2) = 988\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0124696294385551, RMSE on testing set: 1.0293996423175702.\n",
      "iter: 1, RMSE on training set: 1.0046647764681218, RMSE on testing set: 1.0223463108950068.\n",
      "iter: 2, RMSE on training set: 1.0013085996300142, RMSE on testing set: 1.0202983693408814.\n",
      "iter: 3, RMSE on training set: 0.9975265701588858, RMSE on testing set: 1.016358932699165.\n",
      "iter: 4, RMSE on training set: 0.9945228826446831, RMSE on testing set: 1.0137127335516585.\n",
      "iter: 5, RMSE on training set: 0.9922085542101097, RMSE on testing set: 1.012210352211038.\n",
      "iter: 6, RMSE on training set: 0.989404326155573, RMSE on testing set: 1.0099997713294524.\n",
      "iter: 7, RMSE on training set: 0.9886277639804228, RMSE on testing set: 1.0091427903779644.\n",
      "iter: 8, RMSE on training set: 0.986495837458069, RMSE on testing set: 1.0071088062335487.\n",
      "iter: 9, RMSE on training set: 0.9857298747525908, RMSE on testing set: 1.0064480898189183.\n",
      "iter: 10, RMSE on training set: 0.9852331100220331, RMSE on testing set: 1.0063411483956284.\n",
      "iter: 11, RMSE on training set: 0.9839795363778865, RMSE on testing set: 1.0056401901583065.\n",
      "iter: 12, RMSE on training set: 0.9836859114054434, RMSE on testing set: 1.0052735187632749.\n",
      "iter: 13, RMSE on training set: 0.9829484034470646, RMSE on testing set: 1.0046852179172343.\n",
      "iter: 14, RMSE on training set: 0.9826584892452646, RMSE on testing set: 1.0046129716549836.\n",
      "iter: 15, RMSE on training set: 0.9819661202249854, RMSE on testing set: 1.0041025010173028.\n",
      "iter: 16, RMSE on training set: 0.9820019351694041, RMSE on testing set: 1.0041085994369119.\n",
      "RMSE on test data: 1.0041025010173028.\n",
      "seed (1/2) = 988\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0114995875940536, RMSE on testing set: 1.0284007702958837.\n",
      "iter: 1, RMSE on training set: 1.0030730437505122, RMSE on testing set: 1.0207821822777459.\n",
      "iter: 2, RMSE on training set: 0.9992815097603701, RMSE on testing set: 1.0181536740238002.\n",
      "iter: 3, RMSE on training set: 0.9954988787514976, RMSE on testing set: 1.014257900885786.\n",
      "iter: 4, RMSE on training set: 0.992634668300941, RMSE on testing set: 1.0116528578290993.\n",
      "iter: 5, RMSE on training set: 0.9905371727489442, RMSE on testing set: 1.010278147432045.\n",
      "iter: 6, RMSE on training set: 0.988214529311042, RMSE on testing set: 1.0083224762479244.\n",
      "iter: 7, RMSE on training set: 0.9875702382241371, RMSE on testing set: 1.0075458665173163.\n",
      "iter: 8, RMSE on training set: 0.9860748119030602, RMSE on testing set: 1.0061434942752476.\n",
      "iter: 9, RMSE on training set: 0.98568168174338, RMSE on testing set: 1.0057915802575905.\n",
      "iter: 10, RMSE on training set: 0.9853835491626572, RMSE on testing set: 1.0057178360909338.\n",
      "iter: 11, RMSE on training set: 0.9845888613851913, RMSE on testing set: 1.0052558727823586.\n",
      "iter: 12, RMSE on training set: 0.9844825150804235, RMSE on testing set: 1.0050730567596702.\n",
      "iter: 13, RMSE on training set: 0.9839691225166193, RMSE on testing set: 1.0046481262399023.\n",
      "iter: 14, RMSE on training set: 0.9838325343930957, RMSE on testing set: 1.0045828717183818.\n",
      "iter: 15, RMSE on training set: 0.9834764005594958, RMSE on testing set: 1.0043608642670756.\n",
      "iter: 16, RMSE on training set: 0.9835187199607809, RMSE on testing set: 1.004382362272196.\n",
      "RMSE on test data: 1.0043608642670756.\n",
      "seed (1/2) = 988\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0106203397134645, RMSE on testing set: 1.027490257259821.\n",
      "iter: 1, RMSE on training set: 1.0016907885723934, RMSE on testing set: 1.0194207078689377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 2, RMSE on training set: 0.9976054099661935, RMSE on testing set: 1.016374901939589.\n",
      "iter: 3, RMSE on training set: 0.993908819271057, RMSE on testing set: 1.0126041925634646.\n",
      "iter: 4, RMSE on training set: 0.9912361759613241, RMSE on testing set: 1.0101045792010845.\n",
      "iter: 5, RMSE on training set: 0.9893921338888254, RMSE on testing set: 1.0089037345509304.\n",
      "iter: 6, RMSE on training set: 0.9874647992371139, RMSE on testing set: 1.0071944648131763.\n",
      "iter: 7, RMSE on training set: 0.9869749403984214, RMSE on testing set: 1.0065802661569163.\n",
      "iter: 8, RMSE on training set: 0.9859207210515455, RMSE on testing set: 1.0056340792067484.\n",
      "iter: 9, RMSE on training set: 0.9857196030438562, RMSE on testing set: 1.005421266527829.\n",
      "iter: 10, RMSE on training set: 0.9855137737626929, RMSE on testing set: 1.0053592454053697.\n",
      "iter: 11, RMSE on training set: 0.9850019102488605, RMSE on testing set: 1.0050287561983213.\n",
      "iter: 12, RMSE on training set: 0.9849856562073047, RMSE on testing set: 1.004962800119415.\n",
      "RMSE on test data: 1.004962800119415.\n",
      "seed (1/2) = 988\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0375586033709128, RMSE on testing set: 1.0545816023935706.\n",
      "iter: 1, RMSE on training set: 1.0287661326180957, RMSE on testing set: 1.0464513365970534.\n",
      "iter: 2, RMSE on training set: 1.0248400597452454, RMSE on testing set: 1.0457793194677831.\n",
      "iter: 3, RMSE on training set: 1.0167812913877172, RMSE on testing set: 1.0379748990064526.\n",
      "iter: 4, RMSE on training set: 1.009644993846298, RMSE on testing set: 1.0327091864290063.\n",
      "iter: 5, RMSE on training set: 1.002323454892216, RMSE on testing set: 1.0285654262601893.\n",
      "iter: 6, RMSE on training set: 0.9919882021422252, RMSE on testing set: 1.0221208552898664.\n",
      "iter: 7, RMSE on training set: 0.9878721661333781, RMSE on testing set: 1.0210589445060492.\n",
      "iter: 8, RMSE on training set: 0.9790128309566458, RMSE on testing set: 1.014512307549859.\n",
      "iter: 9, RMSE on training set: 0.9720690018869153, RMSE on testing set: 1.0098050818550461.\n",
      "iter: 10, RMSE on training set: 0.9675714784940946, RMSE on testing set: 1.0085570008437335.\n",
      "iter: 11, RMSE on training set: 0.9616249296859685, RMSE on testing set: 1.0058462282796508.\n",
      "iter: 12, RMSE on training set: 0.9571237205335045, RMSE on testing set: 1.0032140890106915.\n",
      "iter: 13, RMSE on training set: 0.9540601186244887, RMSE on testing set: 1.001312039002445.\n",
      "iter: 14, RMSE on training set: 0.9504490646044454, RMSE on testing set: 1.0003710623905164.\n",
      "iter: 15, RMSE on training set: 0.9474194180280625, RMSE on testing set: 0.9991684704560665.\n",
      "iter: 16, RMSE on training set: 0.9444414008349773, RMSE on testing set: 0.9972991248594961.\n",
      "iter: 17, RMSE on training set: 0.9416953845270618, RMSE on testing set: 0.9960114286161614.\n",
      "iter: 18, RMSE on training set: 0.9391212596487764, RMSE on testing set: 0.9951695631981191.\n",
      "iter: 19, RMSE on training set: 0.9369781568452373, RMSE on testing set: 0.993461810250302.\n",
      "iter: 20, RMSE on training set: 0.9353204598070092, RMSE on testing set: 0.993887022578712.\n",
      "iter: 21, RMSE on training set: 0.9338913980241921, RMSE on testing set: 0.9929594000212878.\n",
      "iter: 22, RMSE on training set: 0.9325981055596938, RMSE on testing set: 0.9919025303301767.\n",
      "iter: 23, RMSE on training set: 0.9315293472425988, RMSE on testing set: 0.9921477339871339.\n",
      "iter: 24, RMSE on training set: 0.9306219537693765, RMSE on testing set: 0.9919952720650334.\n",
      "iter: 25, RMSE on training set: 0.9298447808371532, RMSE on testing set: 0.9916861367684371.\n",
      "iter: 26, RMSE on training set: 0.9284683163012494, RMSE on testing set: 0.9907042587182625.\n",
      "iter: 27, RMSE on training set: 0.9278192824978763, RMSE on testing set: 0.9905101518302755.\n",
      "iter: 28, RMSE on training set: 0.9267463143866552, RMSE on testing set: 0.9901627757897322.\n",
      "iter: 29, RMSE on training set: 0.9266774090224124, RMSE on testing set: 0.9903623399286804.\n",
      "RMSE on test data: 0.9901627757897322.\n",
      "seed (1/2) = 988\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0352204774583182, RMSE on testing set: 1.0522492133506174.\n",
      "iter: 1, RMSE on training set: 1.0246674002133016, RMSE on testing set: 1.0423589863166647.\n",
      "iter: 2, RMSE on training set: 1.0194581122119757, RMSE on testing set: 1.0400949935112003.\n",
      "iter: 3, RMSE on training set: 1.011380145026422, RMSE on testing set: 1.032085166119672.\n",
      "iter: 4, RMSE on training set: 1.0045642600319937, RMSE on testing set: 1.0266891389746415.\n",
      "iter: 5, RMSE on training set: 0.9983933044094238, RMSE on testing set: 1.0227982581283241.\n",
      "iter: 6, RMSE on training set: 0.9901072736512555, RMSE on testing set: 1.0172110053579468.\n",
      "iter: 7, RMSE on training set: 0.9865673252095039, RMSE on testing set: 1.015413647537051.\n",
      "iter: 8, RMSE on training set: 0.9795444209316306, RMSE on testing set: 1.0097885442139505.\n",
      "iter: 9, RMSE on training set: 0.97471394892856, RMSE on testing set: 1.0061875948860615.\n",
      "iter: 10, RMSE on training set: 0.9714913327559563, RMSE on testing set: 1.005044249191308.\n",
      "iter: 11, RMSE on training set: 0.9670998028370943, RMSE on testing set: 1.00265670277033.\n",
      "iter: 12, RMSE on training set: 0.9643590217129342, RMSE on testing set: 1.0007984821676184.\n",
      "iter: 13, RMSE on training set: 0.9621202823652192, RMSE on testing set: 0.9995235133747219.\n",
      "iter: 14, RMSE on training set: 0.9600859014250888, RMSE on testing set: 0.9987988501217857.\n",
      "iter: 15, RMSE on training set: 0.9579447791106672, RMSE on testing set: 0.9975660437933321.\n",
      "iter: 16, RMSE on training set: 0.9567035926460387, RMSE on testing set: 0.9967646925612467.\n",
      "iter: 17, RMSE on training set: 0.9549688785516678, RMSE on testing set: 0.9958931554464251.\n",
      "iter: 18, RMSE on training set: 0.9538277453036457, RMSE on testing set: 0.9953510123308195.\n",
      "iter: 19, RMSE on training set: 0.953025684541232, RMSE on testing set: 0.9948714274445383.\n",
      "iter: 20, RMSE on training set: 0.9521480731483912, RMSE on testing set: 0.9947427650774323.\n",
      "iter: 21, RMSE on training set: 0.9513961577782208, RMSE on testing set: 0.9941821660406517.\n",
      "iter: 22, RMSE on training set: 0.9507828682639278, RMSE on testing set: 0.9938027965086126.\n",
      "iter: 23, RMSE on training set: 0.9504439928868468, RMSE on testing set: 0.9938625194436257.\n",
      "iter: 24, RMSE on training set: 0.9500310235587752, RMSE on testing set: 0.9936596529506965.\n",
      "iter: 25, RMSE on training set: 0.9498166668788298, RMSE on testing set: 0.9936526819283648.\n",
      "iter: 26, RMSE on training set: 0.9492497471984948, RMSE on testing set: 0.9932002025055354.\n",
      "iter: 27, RMSE on training set: 0.9490481485130658, RMSE on testing set: 0.9931661836048461.\n",
      "iter: 28, RMSE on training set: 0.948671781991288, RMSE on testing set: 0.9929691104560058.\n",
      "iter: 29, RMSE on training set: 0.9486438667952123, RMSE on testing set: 0.9930569337063762.\n",
      "RMSE on test data: 0.9929691104560058.\n",
      "seed (1/2) = 988\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0330852799794308, RMSE on testing set: 1.0501193205060289.\n",
      "iter: 1, RMSE on training set: 1.021111757028865, RMSE on testing set: 1.0388181495502713.\n",
      "iter: 2, RMSE on training set: 1.0149303565196544, RMSE on testing set: 1.0353035942836857.\n",
      "iter: 3, RMSE on training set: 1.0069677149368914, RMSE on testing set: 1.0273091911672363.\n",
      "iter: 4, RMSE on training set: 1.0005753975530176, RMSE on testing set: 1.0220215519756224.\n",
      "iter: 5, RMSE on training set: 0.9952734580892398, RMSE on testing set: 1.018415819012342.\n",
      "iter: 6, RMSE on training set: 0.9888288413507117, RMSE on testing set: 1.0138050256163722.\n",
      "iter: 7, RMSE on training set: 0.9861234090364613, RMSE on testing set: 1.011922181886966.\n",
      "iter: 8, RMSE on training set: 0.9809807458768065, RMSE on testing set: 1.0075233462499673.\n",
      "iter: 9, RMSE on training set: 0.9779465873618474, RMSE on testing set: 1.0051485682468126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 10, RMSE on training set: 0.9759236926778029, RMSE on testing set: 1.0043466867104356.\n",
      "iter: 11, RMSE on training set: 0.9729879385670273, RMSE on testing set: 1.0026483544514464.\n",
      "iter: 12, RMSE on training set: 0.9715679540087122, RMSE on testing set: 1.0015480751140644.\n",
      "iter: 13, RMSE on training set: 0.970010835859183, RMSE on testing set: 1.0005617337212973.\n",
      "iter: 14, RMSE on training set: 0.9689802525929153, RMSE on testing set: 1.0001780382472714.\n",
      "iter: 15, RMSE on training set: 0.9675683403422192, RMSE on testing set: 0.9992110585704738.\n",
      "iter: 16, RMSE on training set: 0.9671423278134528, RMSE on testing set: 0.9989288284013965.\n",
      "iter: 17, RMSE on training set: 0.9661970279488611, RMSE on testing set: 0.9983884343169496.\n",
      "iter: 18, RMSE on training set: 0.9658058808147756, RMSE on testing set: 0.9981946137417255.\n",
      "iter: 19, RMSE on training set: 0.9654386513763039, RMSE on testing set: 0.9980057415992654.\n",
      "iter: 20, RMSE on training set: 0.9650747340471068, RMSE on testing set: 0.9978983811987836.\n",
      "iter: 21, RMSE on training set: 0.9647925399158908, RMSE on testing set: 0.9976483653434373.\n",
      "iter: 22, RMSE on training set: 0.9644938431602007, RMSE on testing set: 0.9974810438401702.\n",
      "iter: 23, RMSE on training set: 0.9643889525429341, RMSE on testing set: 0.9974932419709506.\n",
      "iter: 24, RMSE on training set: 0.9642397347785433, RMSE on testing set: 0.9973953121725698.\n",
      "iter: 25, RMSE on training set: 0.9641581119249818, RMSE on testing set: 0.9973514251443987.\n",
      "RMSE on test data: 0.9973514251443987.\n",
      "seed (1/2) = 988\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0311286450810269, RMSE on testing set: 1.048167267780068.\n",
      "iter: 1, RMSE on training set: 1.0180080303968528, RMSE on testing set: 1.0357349665005378.\n",
      "iter: 2, RMSE on training set: 1.0111121358924773, RMSE on testing set: 1.0312525831172485.\n",
      "iter: 3, RMSE on training set: 1.003361137116982, RMSE on testing set: 1.0234210100541754.\n",
      "iter: 4, RMSE on training set: 0.9974249342457748, RMSE on testing set: 1.0183565213419048.\n",
      "iter: 5, RMSE on training set: 0.9928096208309998, RMSE on testing set: 1.0150674485744131.\n",
      "iter: 6, RMSE on training set: 0.9877735135032925, RMSE on testing set: 1.0112640461441815.\n",
      "iter: 7, RMSE on training set: 0.985746380555551, RMSE on testing set: 1.0095296358983452.\n",
      "iter: 8, RMSE on training set: 0.9821602038538164, RMSE on testing set: 1.0063231525869842.\n",
      "iter: 9, RMSE on training set: 0.9804325290403756, RMSE on testing set: 1.0049580685272077.\n",
      "iter: 10, RMSE on training set: 0.9792960011152962, RMSE on testing set: 1.0044848539972768.\n",
      "iter: 11, RMSE on training set: 0.9774964893351822, RMSE on testing set: 1.0034476808253319.\n",
      "iter: 12, RMSE on training set: 0.9768408010980757, RMSE on testing set: 1.002849864867114.\n",
      "iter: 13, RMSE on training set: 0.9758368362065266, RMSE on testing set: 1.002110047024701.\n",
      "iter: 14, RMSE on training set: 0.9753431448870126, RMSE on testing set: 1.0019228396720177.\n",
      "iter: 15, RMSE on training set: 0.9745282262960612, RMSE on testing set: 1.0013522979525016.\n",
      "iter: 16, RMSE on training set: 0.974435929545012, RMSE on testing set: 1.0012955954550729.\n",
      "RMSE on test data: 1.0012955954550729.\n",
      "seed (1/2) = 988\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0293299988672997, RMSE on testing set: 1.04637227355197.\n",
      "iter: 1, RMSE on training set: 1.0152840381962365, RMSE on testing set: 1.0330350870185234.\n",
      "iter: 2, RMSE on training set: 1.0078843763470748, RMSE on testing set: 1.0278177723755977.\n",
      "iter: 3, RMSE on training set: 1.0004146011253658, RMSE on testing set: 1.0202492840144899.\n",
      "iter: 4, RMSE on training set: 0.9949476329298989, RMSE on testing set: 1.0154698305715795.\n",
      "iter: 5, RMSE on training set: 0.9909286226301836, RMSE on testing set: 1.0125350676059997.\n",
      "iter: 6, RMSE on training set: 0.9869353728906625, RMSE on testing set: 1.0093558556812434.\n",
      "iter: 7, RMSE on training set: 0.9854084185907181, RMSE on testing set: 1.0078649332459966.\n",
      "iter: 8, RMSE on training set: 0.9829372135634108, RMSE on testing set: 1.0056214993824633.\n",
      "iter: 9, RMSE on training set: 0.9819957229984875, RMSE on testing set: 1.0048759972528392.\n",
      "iter: 10, RMSE on training set: 0.9813553553256626, RMSE on testing set: 1.0046050054424325.\n",
      "iter: 11, RMSE on training set: 0.9802538041858401, RMSE on testing set: 1.0039631584719946.\n",
      "iter: 12, RMSE on training set: 0.9799682408570457, RMSE on testing set: 1.003652821455081.\n",
      "iter: 13, RMSE on training set: 0.9793219260660208, RMSE on testing set: 1.0031465866718363.\n",
      "iter: 14, RMSE on training set: 0.97909428638698, RMSE on testing set: 1.0030314877157915.\n",
      "iter: 15, RMSE on training set: 0.9786866831528853, RMSE on testing set: 1.0027816220230996.\n",
      "iter: 16, RMSE on training set: 0.9786750117417489, RMSE on testing set: 1.002775352482615.\n",
      "RMSE on test data: 1.002775352482615.\n",
      "seed (1/2) = 988\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.080538397091892, RMSE on testing set: 1.0976359917050855.\n",
      "iter: 1, RMSE on training set: 1.0680700109950936, RMSE on testing set: 1.0868910099624245.\n",
      "iter: 2, RMSE on training set: 1.054598822679846, RMSE on testing set: 1.0795395529989773.\n",
      "iter: 3, RMSE on training set: 1.0354140461193044, RMSE on testing set: 1.0638179751387964.\n",
      "iter: 4, RMSE on training set: 1.0215133657544646, RMSE on testing set: 1.0548458058469807.\n",
      "iter: 5, RMSE on training set: 1.0049479366877176, RMSE on testing set: 1.0450564025599498.\n",
      "iter: 6, RMSE on training set: 0.9886059970954918, RMSE on testing set: 1.0359066778072423.\n",
      "iter: 7, RMSE on training set: 0.9829930087818666, RMSE on testing set: 1.0360378049753385.\n",
      "iter: 8, RMSE on training set: 0.9697835145976064, RMSE on testing set: 1.0267116833886025.\n",
      "iter: 9, RMSE on training set: 0.9588958295512713, RMSE on testing set: 1.0197962169383947.\n",
      "iter: 10, RMSE on training set: 0.9525199273383609, RMSE on testing set: 1.017909910999231.\n",
      "iter: 11, RMSE on training set: 0.9443562046323779, RMSE on testing set: 1.0141686455797518.\n",
      "iter: 12, RMSE on training set: 0.9381484865815884, RMSE on testing set: 1.0104708872565051.\n",
      "iter: 13, RMSE on training set: 0.9339348608351649, RMSE on testing set: 1.006761567486126.\n",
      "iter: 14, RMSE on training set: 0.9295832379924959, RMSE on testing set: 1.0060171445517436.\n",
      "iter: 15, RMSE on training set: 0.9256911837398715, RMSE on testing set: 1.0044329307068505.\n",
      "iter: 16, RMSE on training set: 0.9211970011426699, RMSE on testing set: 1.0009651725795798.\n",
      "iter: 17, RMSE on training set: 0.9184441725465864, RMSE on testing set: 0.999615857737355.\n",
      "iter: 18, RMSE on training set: 0.9148570500683038, RMSE on testing set: 0.9982920178928751.\n",
      "iter: 19, RMSE on training set: 0.911937639167747, RMSE on testing set: 0.9952835993925844.\n",
      "iter: 20, RMSE on training set: 0.9101737356737686, RMSE on testing set: 0.9962388411722944.\n",
      "iter: 21, RMSE on training set: 0.9084255508169913, RMSE on testing set: 0.9946036035141136.\n",
      "iter: 22, RMSE on training set: 0.9070877188226288, RMSE on testing set: 0.9931171346940733.\n",
      "iter: 23, RMSE on training set: 0.9056751829265592, RMSE on testing set: 0.9934941671314936.\n",
      "iter: 24, RMSE on training set: 0.9047694026797978, RMSE on testing set: 0.9933392826173276.\n",
      "iter: 25, RMSE on training set: 0.9038386081723883, RMSE on testing set: 0.9926408404436022.\n",
      "iter: 26, RMSE on training set: 0.9023132235332995, RMSE on testing set: 0.9914365205896317.\n",
      "iter: 27, RMSE on training set: 0.9014758693918633, RMSE on testing set: 0.9910281777079243.\n",
      "iter: 28, RMSE on training set: 0.9000951667918191, RMSE on testing set: 0.9904844677029663.\n",
      "iter: 29, RMSE on training set: 0.9001970731903368, RMSE on testing set: 0.9906568599123297.\n",
      "RMSE on test data: 0.9904844677029663.\n",
      "seed (1/2) = 988\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.076170387217374, RMSE on testing set: 1.0932474686778764.\n",
      "iter: 1, RMSE on training set: 1.0599423690200538, RMSE on testing set: 1.078630697348137.\n",
      "iter: 2, RMSE on training set: 1.0456213146300177, RMSE on testing set: 1.0699016701188067.\n",
      "iter: 3, RMSE on training set: 1.0264815451280542, RMSE on testing set: 1.0533030101751368.\n",
      "iter: 4, RMSE on training set: 1.0118013096807237, RMSE on testing set: 1.0428723444337094.\n",
      "iter: 5, RMSE on training set: 0.9972517996010645, RMSE on testing set: 1.0339418237823848.\n",
      "iter: 6, RMSE on training set: 0.9821232371737598, RMSE on testing set: 1.0246492154835796.\n",
      "iter: 7, RMSE on training set: 0.9757749447679065, RMSE on testing set: 1.0226657617174983.\n",
      "iter: 8, RMSE on training set: 0.9644901964428947, RMSE on testing set: 1.0144485913526131.\n",
      "iter: 9, RMSE on training set: 0.9556220343355323, RMSE on testing set: 1.0084684729286084.\n",
      "iter: 10, RMSE on training set: 0.9501213387874933, RMSE on testing set: 1.0064198837805407.\n",
      "iter: 11, RMSE on training set: 0.943655128883482, RMSE on testing set: 1.0032866635191973.\n",
      "iter: 12, RMSE on training set: 0.9387150953383999, RMSE on testing set: 1.0001821261597352.\n",
      "iter: 13, RMSE on training set: 0.9357146109945935, RMSE on testing set: 0.9981683001451621.\n",
      "iter: 14, RMSE on training set: 0.9322260260705291, RMSE on testing set: 0.9970075861072326.\n",
      "iter: 15, RMSE on training set: 0.9294394057371151, RMSE on testing set: 0.9957756926700336.\n",
      "iter: 16, RMSE on training set: 0.9270253535968241, RMSE on testing set: 0.9940958359463985.\n",
      "iter: 17, RMSE on training set: 0.9246243830071506, RMSE on testing set: 0.9927965980202568.\n",
      "iter: 18, RMSE on training set: 0.9226916829351006, RMSE on testing set: 0.9920369739961127.\n",
      "iter: 19, RMSE on training set: 0.9213092766521684, RMSE on testing set: 0.9909388861238732.\n",
      "iter: 20, RMSE on training set: 0.9201302879902346, RMSE on testing set: 0.9910537996969948.\n",
      "iter: 21, RMSE on training set: 0.9191752379776726, RMSE on testing set: 0.9903655636946522.\n",
      "iter: 22, RMSE on training set: 0.9184091473886545, RMSE on testing set: 0.9897390178191776.\n",
      "iter: 23, RMSE on training set: 0.917851044373033, RMSE on testing set: 0.9898922409340122.\n",
      "iter: 24, RMSE on training set: 0.9173603070599323, RMSE on testing set: 0.9897044350293221.\n",
      "iter: 25, RMSE on training set: 0.9170429630958822, RMSE on testing set: 0.9896306867582733.\n",
      "iter: 26, RMSE on training set: 0.9162129929527651, RMSE on testing set: 0.9888919316486999.\n",
      "iter: 27, RMSE on training set: 0.9160048249844115, RMSE on testing set: 0.9889378110603635.\n",
      "iter: 28, RMSE on training set: 0.9154182513308396, RMSE on testing set: 0.9886473782383012.\n",
      "iter: 29, RMSE on training set: 0.9154710683522873, RMSE on testing set: 0.9888268856379614.\n",
      "RMSE on test data: 0.9886473782383012.\n",
      "seed (1/2) = 988\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0721878546321035, RMSE on testing set: 1.089247072408482.\n",
      "iter: 1, RMSE on training set: 1.0529669624482836, RMSE on testing set: 1.0715396305290743.\n",
      "iter: 2, RMSE on training set: 1.0381083134978444, RMSE on testing set: 1.0617856443654676.\n",
      "iter: 3, RMSE on training set: 1.0197365018301465, RMSE on testing set: 1.0452255803567099.\n",
      "iter: 4, RMSE on training set: 1.0053841681939044, RMSE on testing set: 1.0344012164470309.\n",
      "iter: 5, RMSE on training set: 0.9927002545103359, RMSE on testing set: 1.026289086718769.\n",
      "iter: 6, RMSE on training set: 0.9794158134126388, RMSE on testing set: 1.0175703210632312.\n",
      "iter: 7, RMSE on training set: 0.9734286595727412, RMSE on testing set: 1.0146399602601917.\n",
      "iter: 8, RMSE on training set: 0.9641192543888678, RMSE on testing set: 1.0075562292229387.\n",
      "iter: 9, RMSE on training set: 0.957596442612901, RMSE on testing set: 1.002924825797989.\n",
      "iter: 10, RMSE on training set: 0.953501105694803, RMSE on testing set: 1.0012638295104273.\n",
      "iter: 11, RMSE on training set: 0.9485933413865756, RMSE on testing set: 0.9986527047100798.\n",
      "iter: 12, RMSE on training set: 0.9454658513645369, RMSE on testing set: 0.9965465368790346.\n",
      "iter: 13, RMSE on training set: 0.9432419665331387, RMSE on testing set: 0.9953232346489435.\n",
      "iter: 14, RMSE on training set: 0.9412033241313297, RMSE on testing set: 0.9945827441938184.\n",
      "iter: 15, RMSE on training set: 0.9391883313177442, RMSE on testing set: 0.9934518008601605.\n",
      "iter: 16, RMSE on training set: 0.9381419524436847, RMSE on testing set: 0.9927710999971334.\n",
      "iter: 17, RMSE on training set: 0.9366303945128392, RMSE on testing set: 0.9919711176157623.\n",
      "iter: 18, RMSE on training set: 0.9357891628842893, RMSE on testing set: 0.9915938278819579.\n",
      "iter: 19, RMSE on training set: 0.9352112846399318, RMSE on testing set: 0.9913031372250615.\n",
      "iter: 20, RMSE on training set: 0.9345839136966201, RMSE on testing set: 0.9911882075007781.\n",
      "iter: 21, RMSE on training set: 0.9340738055126868, RMSE on testing set: 0.9907856340817548.\n",
      "iter: 22, RMSE on training set: 0.9336507755424238, RMSE on testing set: 0.9905645950919948.\n",
      "iter: 23, RMSE on training set: 0.9334665529160369, RMSE on testing set: 0.9906204148463408.\n",
      "iter: 24, RMSE on training set: 0.9332204710148307, RMSE on testing set: 0.9904767513738969.\n",
      "iter: 25, RMSE on training set: 0.933138451278007, RMSE on testing set: 0.9904935246870002.\n",
      "RMSE on test data: 0.9904767513738969.\n",
      "seed (1/2) = 988\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.068541352260854, RMSE on testing set: 1.0855855947619941.\n",
      "iter: 1, RMSE on training set: 1.046930364151224, RMSE on testing set: 1.0654053978235951.\n",
      "iter: 2, RMSE on training set: 1.0317115095060863, RMSE on testing set: 1.0548544594039984.\n",
      "iter: 3, RMSE on training set: 1.0143889489801736, RMSE on testing set: 1.0387953368231035.\n",
      "iter: 4, RMSE on training set: 1.001023643909533, RMSE on testing set: 1.0282813699948754.\n",
      "iter: 5, RMSE on training set: 0.9900181689073718, RMSE on testing set: 1.0209173665541116.\n",
      "iter: 6, RMSE on training set: 0.9787925315022175, RMSE on testing set: 1.013169162853111.\n",
      "iter: 7, RMSE on training set: 0.9735970977202137, RMSE on testing set: 1.0099706801001567.\n",
      "iter: 8, RMSE on training set: 0.9661755327226974, RMSE on testing set: 1.004060356180272.\n",
      "iter: 9, RMSE on training set: 0.9616031731973224, RMSE on testing set: 1.0007142316884408.\n",
      "iter: 10, RMSE on training set: 0.9587865768563678, RMSE on testing set: 0.9995173690183236.\n",
      "iter: 11, RMSE on training set: 0.9553056125423216, RMSE on testing set: 0.9975765056384562.\n",
      "iter: 12, RMSE on training set: 0.9535497972801645, RMSE on testing set: 0.9963074544591929.\n",
      "iter: 13, RMSE on training set: 0.9519135319968794, RMSE on testing set: 0.9953521598137505.\n",
      "iter: 14, RMSE on training set: 0.9508057715945423, RMSE on testing set: 0.9949741782374338.\n",
      "iter: 15, RMSE on training set: 0.9494327248526894, RMSE on testing set: 0.9940916611473642.\n",
      "iter: 16, RMSE on training set: 0.9490357212764557, RMSE on testing set: 0.9938612089706584.\n",
      "iter: 17, RMSE on training set: 0.9481777578325894, RMSE on testing set: 0.9933492902442517.\n",
      "iter: 18, RMSE on training set: 0.9478814527081809, RMSE on testing set: 0.9932589432921008.\n",
      "iter: 19, RMSE on training set: 0.9475511171656944, RMSE on testing set: 0.9930951592653486.\n",
      "iter: 20, RMSE on training set: 0.9472901435959651, RMSE on testing set: 0.993046045591556.\n",
      "iter: 21, RMSE on training set: 0.9471173133603547, RMSE on testing set: 0.9929009366245525.\n",
      "iter: 22, RMSE on training set: 0.9468979649376124, RMSE on testing set: 0.9927817329031126.\n",
      "iter: 23, RMSE on training set: 0.9468358220313617, RMSE on testing set: 0.9928008350775189.\n",
      "RMSE on test data: 0.9927817329031126.\n",
      "seed (1/2) = 988\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, RMSE on training set: 1.0651895030335432, RMSE on testing set: 1.0822216300182217.\n",
      "iter: 1, RMSE on training set: 1.0416664500456587, RMSE on testing set: 1.060060961746787.\n",
      "iter: 2, RMSE on training set: 1.0262117098560728, RMSE on testing set: 1.0488851344392232.\n",
      "iter: 3, RMSE on training set: 1.0099957947513427, RMSE on testing set: 1.0335350301927413.\n",
      "iter: 4, RMSE on training set: 0.9978917733577818, RMSE on testing set: 1.0236994140818747.\n",
      "iter: 5, RMSE on training set: 0.9884373917086673, RMSE on testing set: 1.0170926717339857.\n",
      "iter: 6, RMSE on training set: 0.9792334296415179, RMSE on testing set: 1.0104626644813437.\n",
      "iter: 7, RMSE on training set: 0.9749541740726321, RMSE on testing set: 1.007386839786374.\n",
      "iter: 8, RMSE on training set: 0.969262575929632, RMSE on testing set: 1.0026796094110793.\n",
      "iter: 9, RMSE on training set: 0.9661987674184603, RMSE on testing set: 1.0004321711562538.\n",
      "iter: 10, RMSE on training set: 0.964333289772305, RMSE on testing set: 0.9995947939443653.\n",
      "iter: 11, RMSE on training set: 0.9619857622078942, RMSE on testing set: 0.998279657560451.\n",
      "iter: 12, RMSE on training set: 0.9610089233704088, RMSE on testing set: 0.9975126815754083.\n",
      "iter: 13, RMSE on training set: 0.9598283123096608, RMSE on testing set: 0.9967199843522975.\n",
      "iter: 14, RMSE on training set: 0.9592057097489161, RMSE on testing set: 0.9964993659173345.\n",
      "iter: 15, RMSE on training set: 0.9583471079671799, RMSE on testing set: 0.9959399954743345.\n",
      "iter: 16, RMSE on training set: 0.9581994975721905, RMSE on testing set: 0.9958753979115561.\n",
      "iter: 17, RMSE on training set: 0.9577644929734843, RMSE on testing set: 0.9955582195394687.\n",
      "iter: 18, RMSE on training set: 0.9576737243176185, RMSE on testing set: 0.9955887360274122.\n",
      "RMSE on test data: 0.9955582195394687.\n",
      "seed (1/2) = 988\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.1605501773253792, RMSE on testing set: 1.177097085582675.\n",
      "iter: 1, RMSE on training set: 1.1504661395004918, RMSE on testing set: 1.1694519599048725.\n",
      "iter: 2, RMSE on training set: 1.1177659561185709, RMSE on testing set: 1.1440986964335071.\n",
      "iter: 3, RMSE on training set: 1.0893947325329485, RMSE on testing set: 1.1229816254180005.\n",
      "iter: 4, RMSE on training set: 1.0691124817000108, RMSE on testing set: 1.1077939060231443.\n",
      "iter: 5, RMSE on training set: 1.0388019167530875, RMSE on testing set: 1.0868630213060697.\n",
      "iter: 6, RMSE on training set: 1.016420760059684, RMSE on testing set: 1.0729790693478989.\n",
      "iter: 7, RMSE on training set: 1.0107156425153718, RMSE on testing set: 1.0742267538671102.\n",
      "iter: 8, RMSE on training set: 0.9910772663239179, RMSE on testing set: 1.0592724148999253.\n",
      "iter: 9, RMSE on training set: 0.9773529783026746, RMSE on testing set: 1.04960768204214.\n",
      "iter: 10, RMSE on training set: 0.9682663507390438, RMSE on testing set: 1.045551598070703.\n",
      "iter: 11, RMSE on training set: 0.9545058403525105, RMSE on testing set: 1.0368310381366277.\n",
      "iter: 12, RMSE on training set: 0.9476008282932794, RMSE on testing set: 1.031818118884897.\n",
      "iter: 13, RMSE on training set: 0.9401275519926547, RMSE on testing set: 1.0241452159785622.\n",
      "iter: 14, RMSE on training set: 0.9360683809290052, RMSE on testing set: 1.0244344655630695.\n",
      "iter: 15, RMSE on training set: 0.9292793590016097, RMSE on testing set: 1.0198037272642917.\n",
      "iter: 16, RMSE on training set: 0.922141806523494, RMSE on testing set: 1.013331390671581.\n",
      "iter: 17, RMSE on training set: 0.9195791528877941, RMSE on testing set: 1.0121153702823298.\n",
      "iter: 18, RMSE on training set: 0.914030176887339, RMSE on testing set: 1.009286901762022.\n",
      "iter: 19, RMSE on training set: 0.9098455558843223, RMSE on testing set: 1.0043849963225817.\n",
      "iter: 20, RMSE on training set: 0.9074721975168264, RMSE on testing set: 1.0053325875871946.\n",
      "iter: 21, RMSE on training set: 0.9044284639767274, RMSE on testing set: 1.0021030019991146.\n",
      "iter: 22, RMSE on training set: 0.9027145243223339, RMSE on testing set: 0.999937746426019.\n",
      "iter: 23, RMSE on training set: 0.9003900071425275, RMSE on testing set: 0.9999892885396182.\n",
      "iter: 24, RMSE on training set: 0.899547544663831, RMSE on testing set: 0.9998138460708319.\n",
      "iter: 25, RMSE on training set: 0.8974096846298344, RMSE on testing set: 0.9978410233386205.\n",
      "iter: 26, RMSE on training set: 0.895714794573892, RMSE on testing set: 0.9963807799087246.\n",
      "iter: 27, RMSE on training set: 0.8943610930150256, RMSE on testing set: 0.9955667851933473.\n",
      "iter: 28, RMSE on training set: 0.8922440817161092, RMSE on testing set: 0.9945620159829615.\n",
      "iter: 29, RMSE on training set: 0.8920187175937719, RMSE on testing set: 0.9941794145243307.\n",
      "RMSE on test data: 0.9941794145243307.\n",
      "seed (1/2) = 988\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.1528309567216477, RMSE on testing set: 1.1695664616357755.\n",
      "iter: 1, RMSE on training set: 1.1338003547044566, RMSE on testing set: 1.15323259687059.\n",
      "iter: 2, RMSE on training set: 1.0974328018444157, RMSE on testing set: 1.124668791516211.\n",
      "iter: 3, RMSE on training set: 1.065238543803741, RMSE on testing set: 1.0990487903383461.\n",
      "iter: 4, RMSE on training set: 1.0426115376570007, RMSE on testing set: 1.0822845006485755.\n",
      "iter: 5, RMSE on training set: 1.0146400826022546, RMSE on testing set: 1.0628200814692694.\n",
      "iter: 6, RMSE on training set: 0.992505963229256, RMSE on testing set: 1.0487487282202668.\n",
      "iter: 7, RMSE on training set: 0.9841834877236161, RMSE on testing set: 1.0468369326769076.\n",
      "iter: 8, RMSE on training set: 0.967025304624277, RMSE on testing set: 1.0338107658209401.\n",
      "iter: 9, RMSE on training set: 0.953521401260406, RMSE on testing set: 1.024111241010842.\n",
      "iter: 10, RMSE on training set: 0.9454821528592079, RMSE on testing set: 1.0203893605424024.\n",
      "iter: 11, RMSE on training set: 0.935972357228365, RMSE on testing set: 1.0149640439603986.\n",
      "iter: 12, RMSE on training set: 0.9289928499871375, RMSE on testing set: 1.0101778715156748.\n",
      "iter: 13, RMSE on training set: 0.9242580087316368, RMSE on testing set: 1.005639198999246.\n",
      "iter: 14, RMSE on training set: 0.9196034159011184, RMSE on testing set: 1.00413044626502.\n",
      "iter: 15, RMSE on training set: 0.9156515655103561, RMSE on testing set: 1.0020634466574203.\n",
      "iter: 16, RMSE on training set: 0.9114899693320825, RMSE on testing set: 0.9985926811913135.\n",
      "iter: 17, RMSE on training set: 0.9086424385017218, RMSE on testing set: 0.9967756488780769.\n",
      "iter: 18, RMSE on training set: 0.9055725506803081, RMSE on testing set: 0.99530828001617.\n",
      "iter: 19, RMSE on training set: 0.9033084703940025, RMSE on testing set: 0.9929269530847998.\n",
      "iter: 20, RMSE on training set: 0.9017961633071069, RMSE on testing set: 0.9933282030161662.\n",
      "iter: 21, RMSE on training set: 0.9005553325523535, RMSE on testing set: 0.9921087571760503.\n",
      "iter: 22, RMSE on training set: 0.8995837171318296, RMSE on testing set: 0.9909377707277149.\n",
      "iter: 23, RMSE on training set: 0.8986891324172298, RMSE on testing set: 0.9911595604511957.\n",
      "iter: 24, RMSE on training set: 0.8980974189922537, RMSE on testing set: 0.9908857756233794.\n",
      "iter: 25, RMSE on training set: 0.8976280813972052, RMSE on testing set: 0.9905235772105825.\n",
      "iter: 26, RMSE on training set: 0.896560722600719, RMSE on testing set: 0.9894700900353226.\n",
      "iter: 27, RMSE on training set: 0.8962282134247839, RMSE on testing set: 0.9894217659654457.\n",
      "iter: 28, RMSE on training set: 0.895434486596624, RMSE on testing set: 0.9890209458018512.\n",
      "iter: 29, RMSE on training set: 0.8956254413878019, RMSE on testing set: 0.9892380971746684.\n",
      "RMSE on test data: 0.9890209458018512.\n",
      "seed (1/2) = 988\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.1456318495177895, RMSE on testing set: 1.16251055583711.\n",
      "iter: 1, RMSE on training set: 1.1192008964117028, RMSE on testing set: 1.138906133788332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 2, RMSE on training set: 1.0812488660618647, RMSE on testing set: 1.108844475967468.\n",
      "iter: 3, RMSE on training set: 1.0475514010568039, RMSE on testing set: 1.08087560074516.\n",
      "iter: 4, RMSE on training set: 1.0241890604766577, RMSE on testing set: 1.0634449660258045.\n",
      "iter: 5, RMSE on training set: 0.9995540359001054, RMSE on testing set: 1.046288693408882.\n",
      "iter: 6, RMSE on training set: 0.9789853896115176, RMSE on testing set: 1.0329141417311531.\n",
      "iter: 7, RMSE on training set: 0.9699803460083528, RMSE on testing set: 1.0293224770552254.\n",
      "iter: 8, RMSE on training set: 0.95554361020384, RMSE on testing set: 1.0183794826178483.\n",
      "iter: 9, RMSE on training set: 0.9443598866096158, RMSE on testing set: 1.0102671466232644.\n",
      "iter: 10, RMSE on training set: 0.9377848267370434, RMSE on testing set: 1.0071454045891104.\n",
      "iter: 11, RMSE on training set: 0.9306015141170382, RMSE on testing set: 1.0031684155354772.\n",
      "iter: 12, RMSE on training set: 0.9252531954636226, RMSE on testing set: 0.9994969142569354.\n",
      "iter: 13, RMSE on training set: 0.9221601905623869, RMSE on testing set: 0.9971197545648707.\n",
      "iter: 14, RMSE on training set: 0.918764908192573, RMSE on testing set: 0.9957109125147937.\n",
      "iter: 15, RMSE on training set: 0.9161246293161371, RMSE on testing set: 0.9943197761196186.\n",
      "iter: 16, RMSE on training set: 0.9140890995224517, RMSE on testing set: 0.9927264190889777.\n",
      "iter: 17, RMSE on training set: 0.9119880411245476, RMSE on testing set: 0.9914431830998824.\n",
      "iter: 18, RMSE on training set: 0.9105402197662845, RMSE on testing set: 0.9907457003151627.\n",
      "iter: 19, RMSE on training set: 0.9096297592856746, RMSE on testing set: 0.9900144119329793.\n",
      "iter: 20, RMSE on training set: 0.9087767116477846, RMSE on testing set: 0.9899821926130118.\n",
      "iter: 21, RMSE on training set: 0.9081082792312136, RMSE on testing set: 0.989410476761955.\n",
      "iter: 22, RMSE on training set: 0.9076265747649349, RMSE on testing set: 0.9890381620326418.\n",
      "iter: 23, RMSE on training set: 0.9073377059793704, RMSE on testing set: 0.9891245159617078.\n",
      "iter: 24, RMSE on training set: 0.9070548760778013, RMSE on testing set: 0.9889317520772255.\n",
      "iter: 25, RMSE on training set: 0.9069646225126254, RMSE on testing set: 0.9889667476492621.\n",
      "RMSE on test data: 0.9889317520772255.\n",
      "seed (1/2) = 988\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.1389261923123948, RMSE on testing set: 1.155911070532682.\n",
      "iter: 1, RMSE on training set: 1.1064799744146185, RMSE on testing set: 1.1263315407589125.\n",
      "iter: 2, RMSE on training set: 1.068308127849945, RMSE on testing set: 1.0958914513984692.\n",
      "iter: 3, RMSE on training set: 1.0346176976355923, RMSE on testing set: 1.0670827324194407.\n",
      "iter: 4, RMSE on training set: 1.0114692665819518, RMSE on testing set: 1.0495496325497018.\n",
      "iter: 5, RMSE on training set: 0.9901110136753349, RMSE on testing set: 1.034697821714329.\n",
      "iter: 6, RMSE on training set: 0.9716247696068462, RMSE on testing set: 1.0223587572405703.\n",
      "iter: 7, RMSE on training set: 0.963076014695514, RMSE on testing set: 1.0180613736502093.\n",
      "iter: 8, RMSE on training set: 0.9511515993808091, RMSE on testing set: 1.0089433527153984.\n",
      "iter: 9, RMSE on training set: 0.9426438349374068, RMSE on testing set: 1.0026870778155579.\n",
      "iter: 10, RMSE on training set: 0.9376639959336347, RMSE on testing set: 1.0003100627761292.\n",
      "iter: 11, RMSE on training set: 0.9322114552716639, RMSE on testing set: 0.9972573092156011.\n",
      "iter: 12, RMSE on training set: 0.9287360391851919, RMSE on testing set: 0.9947941316845531.\n",
      "iter: 13, RMSE on training set: 0.9265411573048262, RMSE on testing set: 0.9934839562846942.\n",
      "iter: 14, RMSE on training set: 0.9245425941368051, RMSE on testing set: 0.992656201845478.\n",
      "iter: 15, RMSE on training set: 0.9226644985157655, RMSE on testing set: 0.9915266399767042.\n",
      "iter: 16, RMSE on training set: 0.9218029201240425, RMSE on testing set: 0.9909057367408958.\n",
      "iter: 17, RMSE on training set: 0.9205078716240012, RMSE on testing set: 0.990152885198538.\n",
      "iter: 18, RMSE on training set: 0.919916361218489, RMSE on testing set: 0.9898791110706037.\n",
      "iter: 19, RMSE on training set: 0.919491742237481, RMSE on testing set: 0.989668231580879.\n",
      "iter: 20, RMSE on training set: 0.9190590902613687, RMSE on testing set: 0.9895773543348351.\n",
      "iter: 21, RMSE on training set: 0.9187378128822788, RMSE on testing set: 0.9892873526725011.\n",
      "iter: 22, RMSE on training set: 0.9184493165397589, RMSE on testing set: 0.9891390809779118.\n",
      "iter: 23, RMSE on training set: 0.9183534704294714, RMSE on testing set: 0.9891781637589072.\n",
      "iter: 24, RMSE on training set: 0.9182258836439767, RMSE on testing set: 0.9890901501575771.\n",
      "iter: 25, RMSE on training set: 0.9181836849610824, RMSE on testing set: 0.9890806671680631.\n",
      "RMSE on test data: 0.9890806671680631.\n",
      "seed (1/2) = 988\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.1326851483063134, RMSE on testing set: 1.149746501573036.\n",
      "iter: 1, RMSE on training set: 1.0954104245911778, RMSE on testing set: 1.1153192159585659.\n",
      "iter: 2, RMSE on training set: 1.0578194272577484, RMSE on testing set: 1.0851561451538405.\n",
      "iter: 3, RMSE on training set: 1.0250560687296786, RMSE on testing set: 1.0564941683142846.\n",
      "iter: 4, RMSE on training set: 1.0027511947787886, RMSE on testing set: 1.0392968601489045.\n",
      "iter: 5, RMSE on training set: 0.9842347038428665, RMSE on testing set: 1.0264053903591115.\n",
      "iter: 6, RMSE on training set: 0.9680371102588295, RMSE on testing set: 1.015286432430947.\n",
      "iter: 7, RMSE on training set: 0.9604669333556015, RMSE on testing set: 1.010856767879612.\n",
      "iter: 8, RMSE on training set: 0.9507834337377675, RMSE on testing set: 1.0033065378893944.\n",
      "iter: 9, RMSE on training set: 0.944603022393538, RMSE on testing set: 0.9987249457442335.\n",
      "iter: 10, RMSE on training set: 0.9410815910765794, RMSE on testing set: 0.9970656810597032.\n",
      "iter: 11, RMSE on training set: 0.9371297553766854, RMSE on testing set: 0.9948470842973016.\n",
      "iter: 12, RMSE on training set: 0.935101995741942, RMSE on testing set: 0.993359463919008.\n",
      "iter: 13, RMSE on training set: 0.9334865448759189, RMSE on testing set: 0.9924350731784315.\n",
      "iter: 14, RMSE on training set: 0.9323612141796324, RMSE on testing set: 0.9920301021079969.\n",
      "iter: 15, RMSE on training set: 0.931061984991301, RMSE on testing set: 0.9911836784541858.\n",
      "iter: 16, RMSE on training set: 0.9307306006993689, RMSE on testing set: 0.9909897066496902.\n",
      "iter: 17, RMSE on training set: 0.9299804613203986, RMSE on testing set: 0.990507058687499.\n",
      "iter: 18, RMSE on training set: 0.9297717694626911, RMSE on testing set: 0.9904777175079956.\n",
      "iter: 19, RMSE on training set: 0.9294970652715402, RMSE on testing set: 0.9903281206611859.\n",
      "iter: 20, RMSE on training set: 0.9293237619485555, RMSE on testing set: 0.9903200471598445.\n",
      "iter: 21, RMSE on training set: 0.9292273516622077, RMSE on testing set: 0.9902362734030664.\n",
      "iter: 22, RMSE on training set: 0.9290803720008101, RMSE on testing set: 0.9901528745653904.\n",
      "iter: 23, RMSE on training set: 0.9290474057289472, RMSE on testing set: 0.9901697414613049.\n",
      "RMSE on test data: 0.9901528745653904.\n",
      "seed (2/2) = 1000\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.00373350754926, RMSE on testing set: 1.0197544021145901.\n",
      "iter: 1, RMSE on training set: 0.9982920103821107, RMSE on testing set: 1.016075359802577.\n",
      "iter: 2, RMSE on training set: 0.9963370632657882, RMSE on testing set: 1.014763196365285.\n",
      "iter: 3, RMSE on training set: 0.9946978983957351, RMSE on testing set: 1.011989684116659.\n",
      "iter: 4, RMSE on training set: 0.9932230999870485, RMSE on testing set: 1.012137175290484.\n",
      "iter: 5, RMSE on training set: 0.9919726281694659, RMSE on testing set: 1.0114744572090284.\n",
      "iter: 6, RMSE on training set: 0.9910143557742592, RMSE on testing set: 1.0111588777857428.\n",
      "iter: 7, RMSE on training set: 0.9895626709958044, RMSE on testing set: 1.0093722908433214.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 8, RMSE on training set: 0.9889255503633155, RMSE on testing set: 1.0082509877907915.\n",
      "iter: 9, RMSE on training set: 0.9887503267738482, RMSE on testing set: 1.0081605847907213.\n",
      "iter: 10, RMSE on training set: 0.9875019379945019, RMSE on testing set: 1.007668065867483.\n",
      "iter: 11, RMSE on training set: 0.9865923642852108, RMSE on testing set: 1.007160437274455.\n",
      "iter: 12, RMSE on training set: 0.9854118201000933, RMSE on testing set: 1.0062758052216174.\n",
      "iter: 13, RMSE on training set: 0.9852763890333788, RMSE on testing set: 1.006613045243883.\n",
      "iter: 14, RMSE on training set: 0.9843543236545939, RMSE on testing set: 1.0060942795186918.\n",
      "iter: 15, RMSE on training set: 0.9841140099531585, RMSE on testing set: 1.0059501277461607.\n",
      "iter: 16, RMSE on training set: 0.9831953880702502, RMSE on testing set: 1.005070122827332.\n",
      "iter: 17, RMSE on training set: 0.9832166711129235, RMSE on testing set: 1.0053990410361249.\n",
      "RMSE on test data: 1.005070122827332.\n",
      "seed (2/2) = 1000\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0034005492053748, RMSE on testing set: 1.019354698583729.\n",
      "iter: 1, RMSE on training set: 0.9973197870115857, RMSE on testing set: 1.0150494489053545.\n",
      "iter: 2, RMSE on training set: 0.9950166211427491, RMSE on testing set: 1.0133115836638755.\n",
      "iter: 3, RMSE on training set: 0.9930714291026014, RMSE on testing set: 1.0103407392321695.\n",
      "iter: 4, RMSE on training set: 0.9914543948499924, RMSE on testing set: 1.010314387956353.\n",
      "iter: 5, RMSE on training set: 0.9904029486873005, RMSE on testing set: 1.0095770860776092.\n",
      "iter: 6, RMSE on training set: 0.9894391425562616, RMSE on testing set: 1.0091221108296995.\n",
      "iter: 7, RMSE on training set: 0.9882672876790468, RMSE on testing set: 1.007614486127093.\n",
      "iter: 8, RMSE on training set: 0.9877867866185625, RMSE on testing set: 1.0067846699048706.\n",
      "iter: 9, RMSE on training set: 0.9876353115309364, RMSE on testing set: 1.006707831539919.\n",
      "iter: 10, RMSE on training set: 0.9867898642923653, RMSE on testing set: 1.006305941819335.\n",
      "iter: 11, RMSE on training set: 0.986182823585835, RMSE on testing set: 1.005912272257957.\n",
      "iter: 12, RMSE on training set: 0.9855314917943461, RMSE on testing set: 1.005393620602869.\n",
      "iter: 13, RMSE on training set: 0.9854809840254348, RMSE on testing set: 1.0056576343784425.\n",
      "RMSE on test data: 1.005393620602869.\n",
      "seed (2/2) = 1000\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0031389719876704, RMSE on testing set: 1.0190231776145637.\n",
      "iter: 1, RMSE on training set: 0.9965212699233822, RMSE on testing set: 1.014190607441731.\n",
      "iter: 2, RMSE on training set: 0.9939548475072331, RMSE on testing set: 1.0121280978411635.\n",
      "iter: 3, RMSE on training set: 0.9918775733802425, RMSE on testing set: 1.0091295280938102.\n",
      "iter: 4, RMSE on training set: 0.9902525972784415, RMSE on testing set: 1.0090354880455314.\n",
      "iter: 5, RMSE on training set: 0.9894023401167539, RMSE on testing set: 1.0083071204676473.\n",
      "iter: 6, RMSE on training set: 0.9884877184020787, RMSE on testing set: 1.0078068224804075.\n",
      "iter: 7, RMSE on training set: 0.9875820104873411, RMSE on testing set: 1.0065676899641496.\n",
      "iter: 8, RMSE on training set: 0.9872130553294977, RMSE on testing set: 1.0059854975407676.\n",
      "iter: 9, RMSE on training set: 0.9870757856965615, RMSE on testing set: 1.005967706479191.\n",
      "iter: 10, RMSE on training set: 0.9865206681662826, RMSE on testing set: 1.0056622897912892.\n",
      "iter: 11, RMSE on training set: 0.9861267547577817, RMSE on testing set: 1.005392485694503.\n",
      "iter: 12, RMSE on training set: 0.9857411034636103, RMSE on testing set: 1.0050339603083955.\n",
      "iter: 13, RMSE on training set: 0.9857180046208434, RMSE on testing set: 1.0052301636348437.\n",
      "RMSE on test data: 1.0050339603083955.\n",
      "seed (2/2) = 1000\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0029408959574169, RMSE on testing set: 1.0187525089458633.\n",
      "iter: 1, RMSE on training set: 0.9958702746690865, RMSE on testing set: 1.0134736445732968.\n",
      "iter: 2, RMSE on training set: 0.9931078859616376, RMSE on testing set: 1.011167075782367.\n",
      "iter: 3, RMSE on training set: 0.9910096488902699, RMSE on testing set: 1.0082466308470814.\n",
      "iter: 4, RMSE on training set: 0.9894557207068269, RMSE on testing set: 1.0081420444909415.\n",
      "iter: 5, RMSE on training set: 0.9887740049409347, RMSE on testing set: 1.0074522867350184.\n",
      "iter: 6, RMSE on training set: 0.9879281376062776, RMSE on testing set: 1.0069514909363253.\n",
      "iter: 7, RMSE on training set: 0.9872439822841008, RMSE on testing set: 1.0059436880313506.\n",
      "iter: 8, RMSE on training set: 0.9869499538606195, RMSE on testing set: 1.0055432465870198.\n",
      "iter: 9, RMSE on training set: 0.9868343457667393, RMSE on testing set: 1.0055890741045745.\n",
      "iter: 10, RMSE on training set: 0.9864844688454825, RMSE on testing set: 1.0053626011681378.\n",
      "iter: 11, RMSE on training set: 0.9862314694987144, RMSE on testing set: 1.0051942330249761.\n",
      "iter: 12, RMSE on training set: 0.9859818494304008, RMSE on testing set: 1.004916414944958.\n",
      "iter: 13, RMSE on training set: 0.9859816755974347, RMSE on testing set: 1.0050544566386086.\n",
      "RMSE on test data: 1.004916414944958.\n",
      "seed (2/2) = 1000\n",
      "gamma (1/5) = 0.01\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.002799609456212, RMSE on testing set: 1.0185364529833103.\n",
      "iter: 1, RMSE on training set: 0.9953453862134699, RMSE on testing set: 1.01287798188406.\n",
      "iter: 2, RMSE on training set: 0.992440152184825, RMSE on testing set: 1.0103915039081444.\n",
      "iter: 3, RMSE on training set: 0.9903878496740234, RMSE on testing set: 1.0076100419620595.\n",
      "iter: 4, RMSE on training set: 0.9889427673328787, RMSE on testing set: 1.00751776082487.\n",
      "iter: 5, RMSE on training set: 0.9883872179245797, RMSE on testing set: 1.006872425997103.\n",
      "iter: 6, RMSE on training set: 0.9876193168738043, RMSE on testing set: 1.0063941674124481.\n",
      "iter: 7, RMSE on training set: 0.9871048320046877, RMSE on testing set: 1.005579224177244.\n",
      "iter: 8, RMSE on training set: 0.9868698843651886, RMSE on testing set: 1.0053111116589808.\n",
      "iter: 9, RMSE on training set: 0.9867754063077022, RMSE on testing set: 1.005392276574369.\n",
      "RMSE on test data: 1.0053111116589808.\n",
      "seed (2/2) = 1000\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0137105069144352, RMSE on testing set: 1.0300207814379256.\n",
      "iter: 1, RMSE on training set: 1.0083759631504026, RMSE on testing set: 1.02645690930064.\n",
      "iter: 2, RMSE on training set: 1.0045421684659264, RMSE on testing set: 1.0239798063194139.\n",
      "iter: 3, RMSE on training set: 1.0028035372499964, RMSE on testing set: 1.0208314005048533.\n",
      "iter: 4, RMSE on training set: 0.9998292352982749, RMSE on testing set: 1.019692824509702.\n",
      "iter: 5, RMSE on training set: 0.9962211088874089, RMSE on testing set: 1.0179386840467177.\n",
      "iter: 6, RMSE on training set: 0.9938312971275634, RMSE on testing set: 1.0168399815397147.\n",
      "iter: 7, RMSE on training set: 0.9903128372373354, RMSE on testing set: 1.0133596667188154.\n",
      "iter: 8, RMSE on training set: 0.9878809089024625, RMSE on testing set: 1.0107599520980122.\n",
      "iter: 9, RMSE on training set: 0.9862203300829304, RMSE on testing set: 1.0099315090705963.\n",
      "iter: 10, RMSE on training set: 0.9829158878614642, RMSE on testing set: 1.0083428064380682.\n",
      "iter: 11, RMSE on training set: 0.980496374720566, RMSE on testing set: 1.0071582870218287.\n",
      "iter: 12, RMSE on training set: 0.9773822760967199, RMSE on testing set: 1.0050071980238995.\n",
      "iter: 13, RMSE on training set: 0.9760357567461009, RMSE on testing set: 1.0047560199183545.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 14, RMSE on training set: 0.9736196886797939, RMSE on testing set: 1.0035238624499603.\n",
      "iter: 15, RMSE on training set: 0.9719818983701636, RMSE on testing set: 1.0025053872424532.\n",
      "iter: 16, RMSE on training set: 0.9702147293625308, RMSE on testing set: 1.0013610592566211.\n",
      "iter: 17, RMSE on training set: 0.9691544540596158, RMSE on testing set: 1.0011181666091147.\n",
      "iter: 18, RMSE on training set: 0.9670522846254529, RMSE on testing set: 0.999598121213659.\n",
      "iter: 19, RMSE on training set: 0.9659415348926059, RMSE on testing set: 0.9993852761172966.\n",
      "iter: 20, RMSE on training set: 0.96542020594234, RMSE on testing set: 0.9992628441623216.\n",
      "iter: 21, RMSE on training set: 0.9645525219209549, RMSE on testing set: 0.9987904313090582.\n",
      "iter: 22, RMSE on training set: 0.963425140754242, RMSE on testing set: 0.998121526556485.\n",
      "iter: 23, RMSE on training set: 0.9623615816187486, RMSE on testing set: 0.9971708786444937.\n",
      "iter: 24, RMSE on training set: 0.9619778985477642, RMSE on testing set: 0.9974551033925443.\n",
      "iter: 25, RMSE on training set: 0.9612762329547148, RMSE on testing set: 0.9970342585300669.\n",
      "iter: 26, RMSE on training set: 0.9604038852673985, RMSE on testing set: 0.9964220303764988.\n",
      "iter: 27, RMSE on training set: 0.9599887168079106, RMSE on testing set: 0.9965876440721388.\n",
      "iter: 28, RMSE on training set: 0.9594983962457172, RMSE on testing set: 0.996061039874685.\n",
      "iter: 29, RMSE on training set: 0.9593185780981218, RMSE on testing set: 0.9961277332548847.\n",
      "RMSE on test data: 0.996061039874685.\n",
      "seed (2/2) = 1000\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0125411831524138, RMSE on testing set: 1.0288649227082673.\n",
      "iter: 1, RMSE on training set: 1.0062213523979502, RMSE on testing set: 1.024309019468385.\n",
      "iter: 2, RMSE on training set: 1.0020318110667097, RMSE on testing set: 1.021270286459936.\n",
      "iter: 3, RMSE on training set: 0.9994313483898959, RMSE on testing set: 1.0173230134736169.\n",
      "iter: 4, RMSE on training set: 0.9963885422703042, RMSE on testing set: 1.0160781730994723.\n",
      "iter: 5, RMSE on training set: 0.9933138391204567, RMSE on testing set: 1.0142618053150336.\n",
      "iter: 6, RMSE on training set: 0.9912310409396143, RMSE on testing set: 1.0130973667268635.\n",
      "iter: 7, RMSE on training set: 0.9885749860110223, RMSE on testing set: 1.0102608461789935.\n",
      "iter: 8, RMSE on training set: 0.9870200197007462, RMSE on testing set: 1.008358554860016.\n",
      "iter: 9, RMSE on training set: 0.9860941432209862, RMSE on testing set: 1.0077615462085858.\n",
      "iter: 10, RMSE on training set: 0.9840869547453268, RMSE on testing set: 1.0067849828427804.\n",
      "iter: 11, RMSE on training set: 0.9825984324511703, RMSE on testing set: 1.00590783593679.\n",
      "iter: 12, RMSE on training set: 0.9809204878190918, RMSE on testing set: 1.0046826535647104.\n",
      "iter: 13, RMSE on training set: 0.9803954379541795, RMSE on testing set: 1.0047512775896312.\n",
      "iter: 14, RMSE on training set: 0.979185218188644, RMSE on testing set: 1.0040447227115628.\n",
      "iter: 15, RMSE on training set: 0.9787353387221388, RMSE on testing set: 1.0037737375181839.\n",
      "iter: 16, RMSE on training set: 0.9776221863366898, RMSE on testing set: 1.0027718061767907.\n",
      "iter: 17, RMSE on training set: 0.9775382842991223, RMSE on testing set: 1.0030090322251086.\n",
      "RMSE on test data: 1.0027718061767907.\n",
      "seed (2/2) = 1000\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0114892789548362, RMSE on testing set: 1.0278208051641138.\n",
      "iter: 1, RMSE on training set: 1.0043607904384357, RMSE on testing set: 1.022447511925334.\n",
      "iter: 2, RMSE on training set: 0.9999406130061703, RMSE on testing set: 1.0190057935790326.\n",
      "iter: 3, RMSE on training set: 0.9968172172123317, RMSE on testing set: 1.0146105072916747.\n",
      "iter: 4, RMSE on training set: 0.993802231961927, RMSE on testing set: 1.0133624392164575.\n",
      "iter: 5, RMSE on training set: 0.991259381055179, RMSE on testing set: 1.0116355512801907.\n",
      "iter: 6, RMSE on training set: 0.9894610429503966, RMSE on testing set: 1.0105236179792558.\n",
      "iter: 7, RMSE on training set: 0.9874414016920248, RMSE on testing set: 1.0082371896149986.\n",
      "iter: 8, RMSE on training set: 0.986409049004524, RMSE on testing set: 1.006870769982995.\n",
      "iter: 9, RMSE on training set: 0.9858643728559884, RMSE on testing set: 1.0065029891830986.\n",
      "iter: 10, RMSE on training set: 0.9845998450943242, RMSE on testing set: 1.005847466838139.\n",
      "iter: 11, RMSE on training set: 0.9837068370453699, RMSE on testing set: 1.0052722578178275.\n",
      "iter: 12, RMSE on training set: 0.9828308872167938, RMSE on testing set: 1.0045999569702124.\n",
      "iter: 13, RMSE on training set: 0.982626487181916, RMSE on testing set: 1.004759336440409.\n",
      "iter: 14, RMSE on training set: 0.9820401304946593, RMSE on testing set: 1.0044098850241114.\n",
      "iter: 15, RMSE on training set: 0.9820189177707779, RMSE on testing set: 1.0043575505034008.\n",
      "RMSE on test data: 1.0043575505034008.\n",
      "seed (2/2) = 1000\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0105408843336394, RMSE on testing set: 1.026875021317501.\n",
      "iter: 1, RMSE on training set: 1.002748532249897, RMSE on testing set: 1.020827582733053.\n",
      "iter: 2, RMSE on training set: 0.9981860335488089, RMSE on testing set: 1.0170988089006114.\n",
      "iter: 3, RMSE on training set: 0.9947912641371196, RMSE on testing set: 1.0125121840405369.\n",
      "iter: 4, RMSE on training set: 0.9918950657521816, RMSE on testing set: 1.0113425553959914.\n",
      "iter: 5, RMSE on training set: 0.9898494840810813, RMSE on testing set: 1.009784924511206.\n",
      "iter: 6, RMSE on training set: 0.9883121336971946, RMSE on testing set: 1.0087785929152742.\n",
      "iter: 7, RMSE on training set: 0.9867874947226803, RMSE on testing set: 1.0069490542177728.\n",
      "iter: 8, RMSE on training set: 0.9860811264409954, RMSE on testing set: 1.005993876830837.\n",
      "iter: 9, RMSE on training set: 0.985722379947192, RMSE on testing set: 1.005792773921918.\n",
      "iter: 10, RMSE on training set: 0.9849133845359107, RMSE on testing set: 1.0053393248626803.\n",
      "iter: 11, RMSE on training set: 0.9843674229538963, RMSE on testing set: 1.0049716992851292.\n",
      "iter: 12, RMSE on training set: 0.9838743773682574, RMSE on testing set: 1.004543013188609.\n",
      "iter: 13, RMSE on training set: 0.9837881854211017, RMSE on testing set: 1.004699502451796.\n",
      "RMSE on test data: 1.004543013188609.\n",
      "seed (2/2) = 1000\n",
      "gamma (2/5) = 0.01778279410038923\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.009684252456929, RMSE on testing set: 1.0260162839897082.\n",
      "iter: 1, RMSE on training set: 1.0013475216989907, RMSE on testing set: 1.0194130132543293.\n",
      "iter: 2, RMSE on training set: 0.9967073970365994, RMSE on testing set: 1.015484819094588.\n",
      "iter: 3, RMSE on training set: 0.9932230365358218, RMSE on testing set: 1.0108906880625652.\n",
      "iter: 4, RMSE on training set: 0.9905153726772797, RMSE on testing set: 1.0098536586817792.\n",
      "iter: 5, RMSE on training set: 0.988903429090697, RMSE on testing set: 1.0084894724692615.\n",
      "iter: 6, RMSE on training set: 0.9875875099282853, RMSE on testing set: 1.007596453567399.\n",
      "iter: 7, RMSE on training set: 0.9864489962685773, RMSE on testing set: 1.0061355130633258.\n",
      "iter: 8, RMSE on training set: 0.9859413157144469, RMSE on testing set: 1.0054743910988906.\n",
      "iter: 9, RMSE on training set: 0.9856903776867778, RMSE on testing set: 1.005398366202025.\n",
      "iter: 10, RMSE on training set: 0.9851784396268132, RMSE on testing set: 1.0050796109591935.\n",
      "iter: 11, RMSE on training set: 0.9848383010371821, RMSE on testing set: 1.0048532475222962.\n",
      "iter: 12, RMSE on training set: 0.9845330868369577, RMSE on testing set: 1.0045370071927955.\n",
      "iter: 13, RMSE on training set: 0.9845056339272525, RMSE on testing set: 1.0046628460453386.\n",
      "RMSE on test data: 1.0045370071927955.\n",
      "seed (2/2) = 1000\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (1/5) = 1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0366315356438576, RMSE on testing set: 1.05238086265254.\n",
      "iter: 1, RMSE on training set: 1.0284922797404787, RMSE on testing set: 1.0467453317980062.\n",
      "iter: 2, RMSE on training set: 1.0195239615188145, RMSE on testing set: 1.0410843269024685.\n",
      "iter: 3, RMSE on training set: 1.0170830052656814, RMSE on testing set: 1.0378532894972754.\n",
      "iter: 4, RMSE on training set: 1.00825032991507, RMSE on testing set: 1.031993775646359.\n",
      "iter: 5, RMSE on training set: 0.9989597423152361, RMSE on testing set: 1.0275994550276775.\n",
      "iter: 6, RMSE on training set: 0.9920520382961299, RMSE on testing set: 1.024105389279861.\n",
      "iter: 7, RMSE on training set: 0.9841109289160528, RMSE on testing set: 1.0178753892310455.\n",
      "iter: 8, RMSE on training set: 0.9776483911169144, RMSE on testing set: 1.0126438584100337.\n",
      "iter: 9, RMSE on training set: 0.9735079179558492, RMSE on testing set: 1.0114243265486889.\n",
      "iter: 10, RMSE on training set: 0.9670568530514033, RMSE on testing set: 1.0081243850737955.\n",
      "iter: 11, RMSE on training set: 0.9624518175455751, RMSE on testing set: 1.0064537226786792.\n",
      "iter: 12, RMSE on training set: 0.9572041950908438, RMSE on testing set: 1.00337644708384.\n",
      "iter: 13, RMSE on training set: 0.9541110379484311, RMSE on testing set: 1.002273730966088.\n",
      "iter: 14, RMSE on training set: 0.9498972178823658, RMSE on testing set: 1.0004838725094858.\n",
      "iter: 15, RMSE on training set: 0.9466643161959488, RMSE on testing set: 0.9986200058189538.\n",
      "iter: 16, RMSE on training set: 0.9438104910306587, RMSE on testing set: 0.9973799385924568.\n",
      "iter: 17, RMSE on training set: 0.9416201315004062, RMSE on testing set: 0.9967595640420615.\n",
      "iter: 18, RMSE on training set: 0.9385646798023052, RMSE on testing set: 0.9949789899548547.\n",
      "iter: 19, RMSE on training set: 0.937000730131009, RMSE on testing set: 0.9948213320210304.\n",
      "iter: 20, RMSE on training set: 0.9356211110122935, RMSE on testing set: 0.9943744461445587.\n",
      "iter: 21, RMSE on training set: 0.9342602416833541, RMSE on testing set: 0.9937660994073048.\n",
      "iter: 22, RMSE on training set: 0.932617852017705, RMSE on testing set: 0.9930033769431975.\n",
      "iter: 23, RMSE on training set: 0.9309186449117948, RMSE on testing set: 0.9915968637888197.\n",
      "iter: 24, RMSE on training set: 0.9302818949264493, RMSE on testing set: 0.9922546465525794.\n",
      "iter: 25, RMSE on training set: 0.9291845022374041, RMSE on testing set: 0.9915230884238556.\n",
      "iter: 26, RMSE on training set: 0.927954348402023, RMSE on testing set: 0.9908023232707818.\n",
      "iter: 27, RMSE on training set: 0.927217723785974, RMSE on testing set: 0.9909807752596275.\n",
      "iter: 28, RMSE on training set: 0.9265804456541362, RMSE on testing set: 0.990394539549602.\n",
      "iter: 29, RMSE on training set: 0.9263527095886762, RMSE on testing set: 0.9905817539457051.\n",
      "RMSE on test data: 0.990394539549602.\n",
      "seed (2/2) = 1000\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0342523395165286, RMSE on testing set: 1.0500648427247163.\n",
      "iter: 1, RMSE on training set: 1.0244219899506315, RMSE on testing set: 1.0426948423964073.\n",
      "iter: 2, RMSE on training set: 1.0149134782314708, RMSE on testing set: 1.0360349972576637.\n",
      "iter: 3, RMSE on training set: 1.0112113880257465, RMSE on testing set: 1.0312696857947556.\n",
      "iter: 4, RMSE on training set: 1.0034593757977701, RMSE on testing set: 1.0261081141168218.\n",
      "iter: 5, RMSE on training set: 0.9953749807948098, RMSE on testing set: 1.0216278393709952.\n",
      "iter: 6, RMSE on training set: 0.989650413583357, RMSE on testing set: 1.018288246296111.\n",
      "iter: 7, RMSE on training set: 0.9830992944028026, RMSE on testing set: 1.0126716270144276.\n",
      "iter: 8, RMSE on training set: 0.9784335286784493, RMSE on testing set: 1.0085402769613954.\n",
      "iter: 9, RMSE on training set: 0.9751734263677061, RMSE on testing set: 1.0068663401540554.\n",
      "iter: 10, RMSE on training set: 0.9706109377295663, RMSE on testing set: 1.0045214698187401.\n",
      "iter: 11, RMSE on training set: 0.9673780219307423, RMSE on testing set: 1.0029669716766494.\n",
      "iter: 12, RMSE on training set: 0.9636942241964153, RMSE on testing set: 1.0005054880915691.\n",
      "iter: 13, RMSE on training set: 0.9619868599559814, RMSE on testing set: 1.0000724286054181.\n",
      "iter: 14, RMSE on training set: 0.9594195673005483, RMSE on testing set: 0.9987786309020232.\n",
      "iter: 15, RMSE on training set: 0.9578174636655372, RMSE on testing set: 0.9978561259665772.\n",
      "iter: 16, RMSE on training set: 0.9560528924175287, RMSE on testing set: 0.9966835252531601.\n",
      "iter: 17, RMSE on training set: 0.9552024050711346, RMSE on testing set: 0.9965867330156648.\n",
      "iter: 18, RMSE on training set: 0.9533553403379414, RMSE on testing set: 0.9952433798698755.\n",
      "iter: 19, RMSE on training set: 0.952394886847212, RMSE on testing set: 0.995065533612251.\n",
      "iter: 20, RMSE on training set: 0.9520359933264336, RMSE on testing set: 0.9950447375171818.\n",
      "iter: 21, RMSE on training set: 0.9513902060921549, RMSE on testing set: 0.9946670702300265.\n",
      "iter: 22, RMSE on training set: 0.9506109019811873, RMSE on testing set: 0.9942046623540994.\n",
      "iter: 23, RMSE on training set: 0.9498901208363408, RMSE on testing set: 0.9936052820665092.\n",
      "iter: 24, RMSE on training set: 0.9496724648465598, RMSE on testing set: 0.9937305417911922.\n",
      "iter: 25, RMSE on training set: 0.9492822820005318, RMSE on testing set: 0.9936098872547386.\n",
      "iter: 26, RMSE on training set: 0.9487483994298086, RMSE on testing set: 0.9931695827182052.\n",
      "iter: 27, RMSE on training set: 0.9485333065812014, RMSE on testing set: 0.9933098688772605.\n",
      "iter: 28, RMSE on training set: 0.9482927658172149, RMSE on testing set: 0.9930415754563974.\n",
      "iter: 29, RMSE on training set: 0.9481797957485701, RMSE on testing set: 0.9930757424445329.\n",
      "RMSE on test data: 0.9930415754563974.\n",
      "seed (2/2) = 1000\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0320856625708437, RMSE on testing set: 1.0479561296012296.\n",
      "iter: 1, RMSE on training set: 1.0208758397410478, RMSE on testing set: 1.03916637706483.\n",
      "iter: 2, RMSE on training set: 1.0111098133823153, RMSE on testing set: 1.0318612548498807.\n",
      "iter: 3, RMSE on training set: 1.0065103956775374, RMSE on testing set: 1.0260608907355089.\n",
      "iter: 4, RMSE on training set: 0.999635366275889, RMSE on testing set: 1.0215209002327696.\n",
      "iter: 5, RMSE on training set: 0.9928917867722524, RMSE on testing set: 1.017379945535281.\n",
      "iter: 6, RMSE on training set: 0.988279518567904, RMSE on testing set: 1.0144152878657224.\n",
      "iter: 7, RMSE on training set: 0.9832261138068668, RMSE on testing set: 1.009759302132324.\n",
      "iter: 8, RMSE on training set: 0.9799335644284903, RMSE on testing set: 1.0065791373491106.\n",
      "iter: 9, RMSE on training set: 0.9776929070286227, RMSE on testing set: 1.0051832323453584.\n",
      "iter: 10, RMSE on training set: 0.9745867718552143, RMSE on testing set: 1.0035487883252034.\n",
      "iter: 11, RMSE on training set: 0.9723674286653318, RMSE on testing set: 1.0022881083062745.\n",
      "iter: 12, RMSE on training set: 0.970126992566509, RMSE on testing set: 1.0007224408525648.\n",
      "iter: 13, RMSE on training set: 0.969245015054559, RMSE on testing set: 1.0005891139573124.\n",
      "iter: 14, RMSE on training set: 0.9678121670506343, RMSE on testing set: 0.9997874351397978.\n",
      "iter: 15, RMSE on training set: 0.9672366006658493, RMSE on testing set: 0.9994679545432302.\n",
      "iter: 16, RMSE on training set: 0.9660423316873423, RMSE on testing set: 0.9984597054194964.\n",
      "iter: 17, RMSE on training set: 0.9659273199663653, RMSE on testing set: 0.9986654534149515.\n",
      "iter: 18, RMSE on training set: 0.9649028007378451, RMSE on testing set: 0.997867521229066.\n",
      "iter: 19, RMSE on training set: 0.9643859553679793, RMSE on testing set: 0.9976742660001396.\n",
      "iter: 20, RMSE on training set: 0.964315816102449, RMSE on testing set: 0.997752137869331.\n",
      "RMSE on test data: 0.9976742660001396.\n",
      "seed (2/2) = 1000\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (4/5) = 1.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0301051663987693, RMSE on testing set: 1.0460288249197525.\n",
      "iter: 1, RMSE on training set: 1.0177699582379767, RMSE on testing set: 1.0360751083906508.\n",
      "iter: 2, RMSE on training set: 1.0079404174012414, RMSE on testing set: 1.02837591377164.\n",
      "iter: 3, RMSE on training set: 1.0027315011584508, RMSE on testing set: 1.02191146021097.\n",
      "iter: 4, RMSE on training set: 0.9965490068050225, RMSE on testing set: 1.017899400577585.\n",
      "iter: 5, RMSE on training set: 0.991012700776991, RMSE on testing set: 1.0142090791787692.\n",
      "iter: 6, RMSE on training set: 0.9873414896818622, RMSE on testing set: 1.0116943246477221.\n",
      "iter: 7, RMSE on training set: 0.9836004570568598, RMSE on testing set: 1.0080170902387198.\n",
      "iter: 8, RMSE on training set: 0.9813885129616443, RMSE on testing set: 1.0056999126611192.\n",
      "iter: 9, RMSE on training set: 0.9799927128975255, RMSE on testing set: 1.0047703506506005.\n",
      "iter: 10, RMSE on training set: 0.9779600509456543, RMSE on testing set: 1.0036544578360593.\n",
      "iter: 11, RMSE on training set: 0.9765535201883089, RMSE on testing set: 1.0027858872143567.\n",
      "iter: 12, RMSE on training set: 0.9752840132462663, RMSE on testing set: 1.001863588291347.\n",
      "iter: 13, RMSE on training set: 0.9748266052099723, RMSE on testing set: 1.0018704061596895.\n",
      "iter: 14, RMSE on training set: 0.9740528242910647, RMSE on testing set: 1.0014182316209574.\n",
      "iter: 15, RMSE on training set: 0.9738926656195137, RMSE on testing set: 1.0012866626477066.\n",
      "iter: 16, RMSE on training set: 0.9731367913941694, RMSE on testing set: 1.0005990525359942.\n",
      "iter: 17, RMSE on training set: 0.9731942724157027, RMSE on testing set: 1.0007639163278552.\n",
      "RMSE on test data: 1.0005990525359942.\n",
      "seed (2/2) = 1000\n",
      "gamma (3/5) = 0.03162277660168379\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0282887725948446, RMSE on testing set: 1.044261217379307.\n",
      "iter: 1, RMSE on training set: 1.015036885649775, RMSE on testing set: 1.0333531448410411.\n",
      "iter: 2, RMSE on training set: 1.0052739372126647, RMSE on testing set: 1.0254369483837054.\n",
      "iter: 3, RMSE on training set: 0.9996900256172916, RMSE on testing set: 1.0185917406959475.\n",
      "iter: 4, RMSE on training set: 0.9940839997512524, RMSE on testing set: 1.0150450839355991.\n",
      "iter: 5, RMSE on training set: 0.9895839857824523, RMSE on testing set: 1.0118215728459663.\n",
      "iter: 6, RMSE on training set: 0.9866579676321824, RMSE on testing set: 1.0097341318281836.\n",
      "iter: 7, RMSE on training set: 0.9839130500398202, RMSE on testing set: 1.0068670799327504.\n",
      "iter: 8, RMSE on training set: 0.9824600245138995, RMSE on testing set: 1.0052461569015272.\n",
      "iter: 9, RMSE on training set: 0.9816037779545134, RMSE on testing set: 1.0046916427715722.\n",
      "iter: 10, RMSE on training set: 0.9803170211515883, RMSE on testing set: 1.0039558289258126.\n",
      "iter: 11, RMSE on training set: 0.9794731563434274, RMSE on testing set: 1.0034113123497288.\n",
      "iter: 12, RMSE on training set: 0.9787655267737498, RMSE on testing set: 1.002848905653809.\n",
      "iter: 13, RMSE on training set: 0.9785479817647194, RMSE on testing set: 1.0029290102873352.\n",
      "iter: 14, RMSE on training set: 0.9781497252283482, RMSE on testing set: 1.0027075763196913.\n",
      "iter: 15, RMSE on training set: 0.9781100078555905, RMSE on testing set: 1.0026198612144912.\n",
      "RMSE on test data: 1.0026198612144912.\n",
      "seed (2/2) = 1000\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (1/5) = 1.1\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0818149589204697, RMSE on testing set: 1.0965000332811004.\n",
      "iter: 1, RMSE on training set: 1.0661357553880353, RMSE on testing set: 1.0853156090309735.\n",
      "iter: 2, RMSE on training set: 1.047247092123933, RMSE on testing set: 1.073953509832457.\n",
      "iter: 3, RMSE on training set: 1.0397680144282684, RMSE on testing set: 1.0690349382424549.\n",
      "iter: 4, RMSE on training set: 1.019648658286055, RMSE on testing set: 1.0538514907237464.\n",
      "iter: 5, RMSE on training set: 1.004682923350962, RMSE on testing set: 1.0483312005082808.\n",
      "iter: 6, RMSE on training set: 0.9904221808377935, RMSE on testing set: 1.0404596118657634.\n",
      "iter: 7, RMSE on training set: 0.9784667191570616, RMSE on testing set: 1.0320333435828595.\n",
      "iter: 8, RMSE on training set: 0.9671083991037319, RMSE on testing set: 1.0234500538395075.\n",
      "iter: 9, RMSE on training set: 0.9613382943035361, RMSE on testing set: 1.0228739229304329.\n",
      "iter: 10, RMSE on training set: 0.952600776140837, RMSE on testing set: 1.0178785363044303.\n",
      "iter: 11, RMSE on training set: 0.945204913087223, RMSE on testing set: 1.0148553338467479.\n",
      "iter: 12, RMSE on training set: 0.9389004826460129, RMSE on testing set: 1.0113984576338397.\n",
      "iter: 13, RMSE on training set: 0.9344427706233721, RMSE on testing set: 1.0086088201116643.\n",
      "iter: 14, RMSE on training set: 0.9286613563094316, RMSE on testing set: 1.0059138315702696.\n",
      "iter: 15, RMSE on training set: 0.9244341082986679, RMSE on testing set: 1.0031691608918742.\n",
      "iter: 16, RMSE on training set: 0.9206590380215551, RMSE on testing set: 1.0014473612879107.\n",
      "iter: 17, RMSE on training set: 0.917950556646444, RMSE on testing set: 1.0004215062123554.\n",
      "iter: 18, RMSE on training set: 0.9145113749461561, RMSE on testing set: 0.9984444760582369.\n",
      "iter: 19, RMSE on training set: 0.9129039242125547, RMSE on testing set: 0.9979348815026765.\n",
      "iter: 20, RMSE on training set: 0.9108404804431901, RMSE on testing set: 0.9970840895846261.\n",
      "iter: 21, RMSE on training set: 0.9091664545199865, RMSE on testing set: 0.9957459045099499.\n",
      "iter: 22, RMSE on training set: 0.9076397329856527, RMSE on testing set: 0.995031085864119.\n",
      "iter: 23, RMSE on training set: 0.9052075274995579, RMSE on testing set: 0.9927724468948691.\n",
      "iter: 24, RMSE on training set: 0.9046300115510472, RMSE on testing set: 0.9937802267209955.\n",
      "iter: 25, RMSE on training set: 0.903207091845741, RMSE on testing set: 0.9924660898891696.\n",
      "iter: 26, RMSE on training set: 0.9019179631558819, RMSE on testing set: 0.9915589927270807.\n",
      "iter: 27, RMSE on training set: 0.9009410705736248, RMSE on testing set: 0.9915192039440508.\n",
      "iter: 28, RMSE on training set: 0.9004717861873016, RMSE on testing set: 0.9910817523950909.\n",
      "iter: 29, RMSE on training set: 0.9003035691377304, RMSE on testing set: 0.9911683677055214.\n",
      "RMSE on test data: 0.9910817523950909.\n",
      "seed (2/2) = 1000\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0770837182113453, RMSE on testing set: 1.091868654767921.\n",
      "iter: 1, RMSE on training set: 1.058502170556071, RMSE on testing set: 1.077597293633641.\n",
      "iter: 2, RMSE on training set: 1.0382306530894871, RMSE on testing set: 1.064003780099566.\n",
      "iter: 3, RMSE on training set: 1.0290212901718647, RMSE on testing set: 1.056424035854131.\n",
      "iter: 4, RMSE on training set: 1.010300509666803, RMSE on testing set: 1.0422308114585406.\n",
      "iter: 5, RMSE on training set: 0.9952183989240331, RMSE on testing set: 1.0348573259618374.\n",
      "iter: 6, RMSE on training set: 0.9833220746549096, RMSE on testing set: 1.0280242101947896.\n",
      "iter: 7, RMSE on training set: 0.9721434855148179, RMSE on testing set: 1.0196097830766317.\n",
      "iter: 8, RMSE on training set: 0.9630228289659989, RMSE on testing set: 1.0124851769355756.\n",
      "iter: 9, RMSE on training set: 0.9575221682818419, RMSE on testing set: 1.0106627302825197.\n",
      "iter: 10, RMSE on training set: 0.9498901429100222, RMSE on testing set: 1.006326295474504.\n",
      "iter: 11, RMSE on training set: 0.9445489803537472, RMSE on testing set: 1.0041322123570862.\n",
      "iter: 12, RMSE on training set: 0.9390804458124282, RMSE on testing set: 1.0007825881318382.\n",
      "iter: 13, RMSE on training set: 0.935908354955112, RMSE on testing set: 0.9993692524159323.\n",
      "iter: 14, RMSE on training set: 0.9318468150408611, RMSE on testing set: 0.9974020021005017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 15, RMSE on training set: 0.9289938700266822, RMSE on testing set: 0.995679566796169.\n",
      "iter: 16, RMSE on training set: 0.9265271567965626, RMSE on testing set: 0.9943734059073065.\n",
      "iter: 17, RMSE on training set: 0.9248105595166877, RMSE on testing set: 0.9938131388213528.\n",
      "iter: 18, RMSE on training set: 0.9223948245085514, RMSE on testing set: 0.9922370811733948.\n",
      "iter: 19, RMSE on training set: 0.9212029183697277, RMSE on testing set: 0.9920628210761671.\n",
      "iter: 20, RMSE on training set: 0.9204255101509167, RMSE on testing set: 0.9917727655379388.\n",
      "iter: 21, RMSE on training set: 0.9195534418080438, RMSE on testing set: 0.9913365199642186.\n",
      "iter: 22, RMSE on training set: 0.918467668185552, RMSE on testing set: 0.9907277317871803.\n",
      "iter: 23, RMSE on training set: 0.9174513000357498, RMSE on testing set: 0.989812945098644.\n",
      "iter: 24, RMSE on training set: 0.9171360757811268, RMSE on testing set: 0.9901272963061761.\n",
      "iter: 25, RMSE on training set: 0.9166025508574484, RMSE on testing set: 0.9898267283778961.\n",
      "iter: 26, RMSE on training set: 0.9158732621505882, RMSE on testing set: 0.9892842895742678.\n",
      "iter: 27, RMSE on training set: 0.9155916212623698, RMSE on testing set: 0.989518749528962.\n",
      "iter: 28, RMSE on training set: 0.9152797091773469, RMSE on testing set: 0.9891000574642329.\n",
      "iter: 29, RMSE on training set: 0.9151761421843494, RMSE on testing set: 0.9891784909291179.\n",
      "RMSE on test data: 0.9891000574642329.\n",
      "seed (2/2) = 1000\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0727987781070614, RMSE on testing set: 1.087676340351515.\n",
      "iter: 1, RMSE on training set: 1.0518869009749128, RMSE on testing set: 1.0709124856309826.\n",
      "iter: 2, RMSE on training set: 1.0310028824772535, RMSE on testing set: 1.0559273003196485.\n",
      "iter: 3, RMSE on training set: 1.020907203938045, RMSE on testing set: 1.0466767284288805.\n",
      "iter: 4, RMSE on training set: 1.0039547698234812, RMSE on testing set: 1.0338139695293327.\n",
      "iter: 5, RMSE on training set: 0.9899125206333661, RMSE on testing set: 1.0259578821544584.\n",
      "iter: 6, RMSE on training set: 0.9800382520577271, RMSE on testing set: 1.0199269928350578.\n",
      "iter: 7, RMSE on training set: 0.9703867745850359, RMSE on testing set: 1.012247090541992.\n",
      "iter: 8, RMSE on training set: 0.9634792165505749, RMSE on testing set: 1.0065815604149497.\n",
      "iter: 9, RMSE on training set: 0.958813908404737, RMSE on testing set: 1.004278495114378.\n",
      "iter: 10, RMSE on training set: 0.9531575107319706, RMSE on testing set: 1.0011984599445811.\n",
      "iter: 11, RMSE on training set: 0.9492794452217123, RMSE on testing set: 0.9993832863616253.\n",
      "iter: 12, RMSE on training set: 0.9452489888177393, RMSE on testing set: 0.9967167226767785.\n",
      "iter: 13, RMSE on training set: 0.9433505524961386, RMSE on testing set: 0.9961554603832018.\n",
      "iter: 14, RMSE on training set: 0.9407767463653353, RMSE on testing set: 0.9948279258637067.\n",
      "iter: 15, RMSE on training set: 0.9393527800537871, RMSE on testing set: 0.9940662698059081.\n",
      "iter: 16, RMSE on training set: 0.9376994171938475, RMSE on testing set: 0.9929176570057007.\n",
      "iter: 17, RMSE on training set: 0.9370878549411333, RMSE on testing set: 0.9929328926964817.\n",
      "iter: 18, RMSE on training set: 0.9355414092166598, RMSE on testing set: 0.9917984798771203.\n",
      "iter: 19, RMSE on training set: 0.9347798397901117, RMSE on testing set: 0.9916591623035091.\n",
      "iter: 20, RMSE on training set: 0.9345634796023755, RMSE on testing set: 0.9917022800115781.\n",
      "iter: 21, RMSE on training set: 0.9341371810867101, RMSE on testing set: 0.9914275216922799.\n",
      "iter: 22, RMSE on training set: 0.9336237672015627, RMSE on testing set: 0.9911163117326726.\n",
      "iter: 23, RMSE on training set: 0.9331531373976231, RMSE on testing set: 0.9907398307722244.\n",
      "iter: 24, RMSE on training set: 0.9330547446921154, RMSE on testing set: 0.9908120521662525.\n",
      "iter: 25, RMSE on training set: 0.9328576318049915, RMSE on testing set: 0.9908271897122778.\n",
      "iter: 26, RMSE on training set: 0.9325425326248649, RMSE on testing set: 0.9905255130044964.\n",
      "iter: 27, RMSE on training set: 0.9324301918700154, RMSE on testing set: 0.990606271054439.\n",
      "iter: 28, RMSE on training set: 0.9323358422415455, RMSE on testing set: 0.9905036136548044.\n",
      "iter: 29, RMSE on training set: 0.9322847898275445, RMSE on testing set: 0.9905288361160295.\n",
      "RMSE on test data: 0.9905036136548044.\n",
      "seed (2/2) = 1000\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.068899388475445, RMSE on testing set: 1.0838631122305646.\n",
      "iter: 1, RMSE on training set: 1.0461076068616841, RMSE on testing set: 1.0650779744408223.\n",
      "iter: 2, RMSE on training set: 1.0251040589497553, RMSE on testing set: 1.0492807038775822.\n",
      "iter: 3, RMSE on training set: 1.014645555599164, RMSE on testing set: 1.0390464670791608.\n",
      "iter: 4, RMSE on training set: 0.9995515070976181, RMSE on testing set: 1.0276230720285326.\n",
      "iter: 5, RMSE on training set: 0.9870288291471229, RMSE on testing set: 1.0199985506049964.\n",
      "iter: 6, RMSE on training set: 0.9787998061629158, RMSE on testing set: 1.0146353921372664.\n",
      "iter: 7, RMSE on training set: 0.970890460344474, RMSE on testing set: 1.0080193815542176.\n",
      "iter: 8, RMSE on training set: 0.9657819050581349, RMSE on testing set: 1.003584058116445.\n",
      "iter: 9, RMSE on training set: 0.9622785861445668, RMSE on testing set: 1.0015351472974454.\n",
      "iter: 10, RMSE on training set: 0.9582737633577598, RMSE on testing set: 0.9993835760469775.\n",
      "iter: 11, RMSE on training set: 0.9555107499663992, RMSE on testing set: 0.9979267358829084.\n",
      "iter: 12, RMSE on training set: 0.9529064185550901, RMSE on testing set: 0.9961510142903481.\n",
      "iter: 13, RMSE on training set: 0.9518310903932261, RMSE on testing set: 0.9959411044170846.\n",
      "iter: 14, RMSE on training set: 0.9503136205982746, RMSE on testing set: 0.9951244536319339.\n",
      "iter: 15, RMSE on training set: 0.9497492881692556, RMSE on testing set: 0.9948463213918962.\n",
      "iter: 16, RMSE on training set: 0.9485794602585551, RMSE on testing set: 0.993901231536491.\n",
      "iter: 17, RMSE on training set: 0.948490255687017, RMSE on testing set: 0.9941021768331468.\n",
      "RMSE on test data: 0.993901231536491.\n",
      "seed (2/2) = 1000\n",
      "gamma (4/5) = 0.05623413251903491\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.0653351489187843, RMSE on testing set: 1.080379217468401.\n",
      "iter: 1, RMSE on training set: 1.0410244515605158, RMSE on testing set: 1.0599514454515346.\n",
      "iter: 2, RMSE on training set: 1.020217025598811, RMSE on testing set: 1.0437433184581575.\n",
      "iter: 3, RMSE on training set: 1.0096937917724633, RMSE on testing set: 1.0329805860287982.\n",
      "iter: 4, RMSE on training set: 0.9963974405912979, RMSE on testing set: 1.0229751817216197.\n",
      "iter: 5, RMSE on training set: 0.9855467799707676, RMSE on testing set: 1.0159386585699077.\n",
      "iter: 6, RMSE on training set: 0.9786852692883046, RMSE on testing set: 1.0112092486416853.\n",
      "iter: 7, RMSE on training set: 0.9724072325805249, RMSE on testing set: 1.0057139780448172.\n",
      "iter: 8, RMSE on training set: 0.9686696091263588, RMSE on testing set: 1.0022886324778157.\n",
      "iter: 9, RMSE on training set: 0.9662440418809916, RMSE on testing set: 1.0007703309453453.\n",
      "iter: 10, RMSE on training set: 0.9634435319648036, RMSE on testing set: 0.999228528818013.\n",
      "iter: 11, RMSE on training set: 0.9615816040912258, RMSE on testing set: 0.9981803909246142.\n",
      "iter: 12, RMSE on training set: 0.960005038674637, RMSE on testing set: 0.9970781273185347.\n",
      "iter: 13, RMSE on training set: 0.9593907516090426, RMSE on testing set: 0.9970242915595326.\n",
      "iter: 14, RMSE on training set: 0.9585184582706471, RMSE on testing set: 0.996547187550327.\n",
      "iter: 15, RMSE on training set: 0.9583148312990616, RMSE on testing set: 0.9964066733612261.\n",
      "iter: 16, RMSE on training set: 0.9575557682823662, RMSE on testing set: 0.9957648106062865.\n",
      "iter: 17, RMSE on training set: 0.9575820985905867, RMSE on testing set: 0.9959000493742582.\n",
      "RMSE on test data: 0.9957648106062865.\n",
      "seed (2/2) = 1000\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (1/5) = 1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.1735682353861963, RMSE on testing set: 1.1863181929751254.\n",
      "iter: 1, RMSE on training set: 1.1421076862290616, RMSE on testing set: 1.1611793929617977.\n",
      "iter: 2, RMSE on training set: 1.1132187146891637, RMSE on testing set: 1.1422227030240142.\n",
      "iter: 3, RMSE on training set: 1.0997529304415292, RMSE on testing set: 1.1344670304644886.\n",
      "iter: 4, RMSE on training set: 1.0657662087618185, RMSE on testing set: 1.1048552129692781.\n",
      "iter: 5, RMSE on training set: 1.0480720826953969, RMSE on testing set: 1.1006159070579553.\n",
      "iter: 6, RMSE on training set: 1.0214774531310242, RMSE on testing set: 1.0814697209299706.\n",
      "iter: 7, RMSE on training set: 1.0051789437923622, RMSE on testing set: 1.0689949001492327.\n",
      "iter: 8, RMSE on training set: 0.9870740563190599, RMSE on testing set: 1.054393059835235.\n",
      "iter: 9, RMSE on training set: 0.9773561400489836, RMSE on testing set: 1.0508662659284396.\n",
      "iter: 10, RMSE on training set: 0.9690107501710886, RMSE on testing set: 1.045660152358526.\n",
      "iter: 11, RMSE on training set: 0.9564858288404915, RMSE on testing set: 1.0385125361658796.\n",
      "iter: 12, RMSE on training set: 0.9477412305640782, RMSE on testing set: 1.0323410754419784.\n",
      "iter: 13, RMSE on training set: 0.9412501015814908, RMSE on testing set: 1.0265130240959597.\n",
      "iter: 14, RMSE on training set: 0.9332741660760576, RMSE on testing set: 1.0220310651001003.\n",
      "iter: 15, RMSE on training set: 0.9277223490522485, RMSE on testing set: 1.0178208629371235.\n",
      "iter: 16, RMSE on training set: 0.9218591240624028, RMSE on testing set: 1.0139885919631566.\n",
      "iter: 17, RMSE on training set: 0.9183145536623377, RMSE on testing set: 1.012260682989434.\n",
      "iter: 18, RMSE on training set: 0.9143189885764775, RMSE on testing set: 1.0098040255330265.\n",
      "iter: 19, RMSE on training set: 0.911827989803033, RMSE on testing set: 1.0081275492925794.\n",
      "iter: 20, RMSE on training set: 0.9083004314759597, RMSE on testing set: 1.0061745282095873.\n",
      "iter: 21, RMSE on training set: 0.9056098270666686, RMSE on testing set: 1.003236613359432.\n",
      "iter: 22, RMSE on training set: 0.9040130078978358, RMSE on testing set: 1.0023167479891986.\n",
      "iter: 23, RMSE on training set: 0.8999573383393685, RMSE on testing set: 0.998592257776378.\n",
      "iter: 24, RMSE on training set: 0.899077500836616, RMSE on testing set: 0.9997029630908568.\n",
      "iter: 25, RMSE on training set: 0.8967553701424064, RMSE on testing set: 0.9970718615510142.\n",
      "iter: 26, RMSE on training set: 0.8952781401900409, RMSE on testing set: 0.9960617483131742.\n",
      "iter: 27, RMSE on training set: 0.893942353397477, RMSE on testing set: 0.9956173932905655.\n",
      "iter: 28, RMSE on training set: 0.8932101791634773, RMSE on testing set: 0.9951878249900602.\n",
      "iter: 29, RMSE on training set: 0.8925789095546026, RMSE on testing set: 0.9944974788829958.\n",
      "RMSE on test data: 0.9944974788829958.\n",
      "seed (2/2) = 1000\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (2/5) = 1.1500000000000001\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.164375113134712, RMSE on testing set: 1.1773587762051556.\n",
      "iter: 1, RMSE on training set: 1.126560797580405, RMSE on testing set: 1.1460952820684005.\n",
      "iter: 2, RMSE on training set: 1.092291946952086, RMSE on testing set: 1.1220709274399172.\n",
      "iter: 3, RMSE on training set: 1.074114040211316, RMSE on testing set: 1.1092799170461423.\n",
      "iter: 4, RMSE on training set: 1.0400016827897052, RMSE on testing set: 1.0802286963996952.\n",
      "iter: 5, RMSE on training set: 1.0188223179492517, RMSE on testing set: 1.0711097198201873.\n",
      "iter: 6, RMSE on training set: 0.9953986736183675, RMSE on testing set: 1.0549958228092937.\n",
      "iter: 7, RMSE on training set: 0.979298188630166, RMSE on testing set: 1.0424642686107213.\n",
      "iter: 8, RMSE on training set: 0.9638601335210061, RMSE on testing set: 1.0300990373307224.\n",
      "iter: 9, RMSE on training set: 0.9558212710747903, RMSE on testing set: 1.027305997366285.\n",
      "iter: 10, RMSE on training set: 0.9457263131859593, RMSE on testing set: 1.0205001037072332.\n",
      "iter: 11, RMSE on training set: 0.9367998736195177, RMSE on testing set: 1.0158244161691814.\n",
      "iter: 12, RMSE on training set: 0.9297149831556845, RMSE on testing set: 1.0111241792933026.\n",
      "iter: 13, RMSE on training set: 0.924835484041566, RMSE on testing set: 1.007454928607527.\n",
      "iter: 14, RMSE on training set: 0.918939531720173, RMSE on testing set: 1.0041758704651134.\n",
      "iter: 15, RMSE on training set: 0.9146531455808405, RMSE on testing set: 1.0011157758744558.\n",
      "iter: 16, RMSE on training set: 0.9111224052079994, RMSE on testing set: 0.9989946951297822.\n",
      "iter: 17, RMSE on training set: 0.9085734798527113, RMSE on testing set: 0.9977370870768725.\n",
      "iter: 18, RMSE on training set: 0.9054997469987264, RMSE on testing set: 0.9956701366723559.\n",
      "iter: 19, RMSE on training set: 0.9039795448250302, RMSE on testing set: 0.9949828636425655.\n",
      "iter: 20, RMSE on training set: 0.9026042210011962, RMSE on testing set: 0.9942119861065715.\n",
      "iter: 21, RMSE on training set: 0.9013447126431027, RMSE on testing set: 0.9932199508038362.\n",
      "iter: 22, RMSE on training set: 0.9000582847258327, RMSE on testing set: 0.9923960586827087.\n",
      "iter: 23, RMSE on training set: 0.8985068692305864, RMSE on testing set: 0.990817432414741.\n",
      "iter: 24, RMSE on training set: 0.8981121962216783, RMSE on testing set: 0.9913823860158738.\n",
      "iter: 25, RMSE on training set: 0.8973933217360672, RMSE on testing set: 0.9906977029119945.\n",
      "iter: 26, RMSE on training set: 0.8964351228066388, RMSE on testing set: 0.989893104374515.\n",
      "iter: 27, RMSE on training set: 0.895972327330765, RMSE on testing set: 0.9900304293508095.\n",
      "iter: 28, RMSE on training set: 0.8957104224845303, RMSE on testing set: 0.9895622664978843.\n",
      "iter: 29, RMSE on training set: 0.8956490296682481, RMSE on testing set: 0.9896133383218741.\n",
      "RMSE on test data: 0.9895622664978843.\n",
      "seed (2/2) = 1000\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (3/5) = 1.2000000000000002\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.1558492589219418, RMSE on testing set: 1.1690365394247113.\n",
      "iter: 1, RMSE on training set: 1.1130649531715073, RMSE on testing set: 1.1329013363867546.\n",
      "iter: 2, RMSE on training set: 1.0753246741396778, RMSE on testing set: 1.1052907000065877.\n",
      "iter: 3, RMSE on training set: 1.0547249840752786, RMSE on testing set: 1.0893634445117775.\n",
      "iter: 4, RMSE on training set: 1.0223185096603153, RMSE on testing set: 1.0621929526144487.\n",
      "iter: 5, RMSE on training set: 1.0003969111886453, RMSE on testing set: 1.050755230057603.\n",
      "iter: 6, RMSE on training set: 0.9809030704141108, RMSE on testing set: 1.0377078021323196.\n",
      "iter: 7, RMSE on training set: 0.9660457848860534, RMSE on testing set: 1.0259876096974305.\n",
      "iter: 8, RMSE on training set: 0.9535996600483375, RMSE on testing set: 1.0160447649317461.\n",
      "iter: 9, RMSE on training set: 0.9465766729219377, RMSE on testing set: 1.0130522200027998.\n",
      "iter: 10, RMSE on training set: 0.9376874798515861, RMSE on testing set: 1.0072741377682903.\n",
      "iter: 11, RMSE on training set: 0.9314728449424943, RMSE on testing set: 1.0042019784626668.\n",
      "iter: 12, RMSE on training set: 0.9257299044014561, RMSE on testing set: 1.0003371294514818.\n",
      "iter: 13, RMSE on training set: 0.9224523289100973, RMSE on testing set: 0.9984440803436976.\n",
      "iter: 14, RMSE on training set: 0.9184810859316257, RMSE on testing set: 0.9962326144867957.\n",
      "iter: 15, RMSE on training set: 0.915911297736911, RMSE on testing set: 0.9945596441594008.\n",
      "iter: 16, RMSE on training set: 0.9137205256537387, RMSE on testing set: 0.9931135713235922.\n",
      "iter: 17, RMSE on training set: 0.9124007680680741, RMSE on testing set: 0.992591994594706.\n",
      "iter: 18, RMSE on training set: 0.9104394768217146, RMSE on testing set: 0.9911799316032188.\n",
      "iter: 19, RMSE on training set: 0.9094863395944883, RMSE on testing set: 0.9909456634264998.\n",
      "iter: 20, RMSE on training set: 0.9090928339625978, RMSE on testing set: 0.9908069204848176.\n",
      "iter: 21, RMSE on training set: 0.9084925348500758, RMSE on testing set: 0.9904075487962911.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 22, RMSE on training set: 0.9077944479727176, RMSE on testing set: 0.9899491592216615.\n",
      "iter: 23, RMSE on training set: 0.9071417938802203, RMSE on testing set: 0.9893192751199923.\n",
      "iter: 24, RMSE on training set: 0.9069933429288145, RMSE on testing set: 0.9894676297693932.\n",
      "iter: 25, RMSE on training set: 0.9067495195840831, RMSE on testing set: 0.9894104758080313.\n",
      "iter: 26, RMSE on training set: 0.9062945621120335, RMSE on testing set: 0.9889724495983553.\n",
      "iter: 27, RMSE on training set: 0.9061689948073758, RMSE on testing set: 0.989124603174705.\n",
      "iter: 28, RMSE on training set: 0.9060512636196452, RMSE on testing set: 0.9889219611749384.\n",
      "iter: 29, RMSE on training set: 0.90599450899746, RMSE on testing set: 0.988952637413697.\n",
      "RMSE on test data: 0.9889219611749384.\n",
      "seed (2/2) = 1000\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (4/5) = 1.25\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.147956441869806, RMSE on testing set: 1.1613219991573018.\n",
      "iter: 1, RMSE on training set: 1.1013635646686677, RMSE on testing set: 1.1213825712245327.\n",
      "iter: 2, RMSE on training set: 1.061664986015202, RMSE on testing set: 1.0914220239566477.\n",
      "iter: 3, RMSE on training set: 1.0400429987276547, RMSE on testing set: 1.0736355105147262.\n",
      "iter: 4, RMSE on training set: 1.010124870132754, RMSE on testing set: 1.0488484599308507.\n",
      "iter: 5, RMSE on training set: 0.9889744833643497, RMSE on testing set: 1.0366607039666191.\n",
      "iter: 6, RMSE on training set: 0.9729779320215204, RMSE on testing set: 1.0260091219224514.\n",
      "iter: 7, RMSE on training set: 0.959870034556447, RMSE on testing set: 1.0155197497462958.\n",
      "iter: 8, RMSE on training set: 0.9502352481906511, RMSE on testing set: 1.0077387791069012.\n",
      "iter: 9, RMSE on training set: 0.9442467944996372, RMSE on testing set: 1.004625465747904.\n",
      "iter: 10, RMSE on training set: 0.9374979221723223, RMSE on testing set: 1.0005314061752082.\n",
      "iter: 11, RMSE on training set: 0.9330123407916269, RMSE on testing set: 0.998269147243376.\n",
      "iter: 12, RMSE on training set: 0.9287381655289019, RMSE on testing set: 0.9953260660271426.\n",
      "iter: 13, RMSE on training set: 0.9267429649028961, RMSE on testing set: 0.9945241144929884.\n",
      "iter: 14, RMSE on training set: 0.9242122764260433, RMSE on testing set: 0.9930936957025227.\n",
      "iter: 15, RMSE on training set: 0.9229954784852942, RMSE on testing set: 0.9924339031275625.\n",
      "iter: 16, RMSE on training set: 0.9214735546630242, RMSE on testing set: 0.9912605713304173.\n",
      "iter: 17, RMSE on training set: 0.9210798163672718, RMSE on testing set: 0.9913132445839417.\n",
      "iter: 18, RMSE on training set: 0.9198024137323451, RMSE on testing set: 0.9903498706620716.\n",
      "iter: 19, RMSE on training set: 0.9192024012201986, RMSE on testing set: 0.9901909043450584.\n",
      "iter: 20, RMSE on training set: 0.919100876599299, RMSE on testing set: 0.9902660556255615.\n",
      "iter: 21, RMSE on training set: 0.918833807366155, RMSE on testing set: 0.9900599659543706.\n",
      "iter: 22, RMSE on training set: 0.9185013834863018, RMSE on testing set: 0.9898410394683717.\n",
      "iter: 23, RMSE on training set: 0.9181996047899532, RMSE on testing set: 0.9895920555449766.\n",
      "iter: 24, RMSE on training set: 0.9181651080011553, RMSE on testing set: 0.989642421159248.\n",
      "RMSE on test data: 0.9895920555449766.\n",
      "seed (2/2) = 1000\n",
      "gamma (5/5) = 0.1\n",
      "stepsize decrement (5/5) = 1.3\n",
      "learn the matrix factorization using SGD...\n",
      "initial RMSE on training set: 1.2970036050983964, RMSE on testing set: 1.29779821218469.\n",
      "iter: 0, RMSE on training set: 1.1406573686699661, RMSE on testing set: 1.154180028666408.\n",
      "iter: 1, RMSE on training set: 1.0911946612586134, RMSE on testing set: 1.1113119765592399.\n",
      "iter: 2, RMSE on training set: 1.050658634837696, RMSE on testing set: 1.079963353901246.\n",
      "iter: 3, RMSE on training set: 1.0288494567487054, RMSE on testing set: 1.061168237411366.\n",
      "iter: 4, RMSE on training set: 1.0016847050809576, RMSE on testing set: 1.0388871978378367.\n",
      "iter: 5, RMSE on training set: 0.9821475921823778, RMSE on testing set: 1.026914690795914.\n",
      "iter: 6, RMSE on training set: 0.968947344970504, RMSE on testing set: 1.0179879297268408.\n",
      "iter: 7, RMSE on training set: 0.9577960991328109, RMSE on testing set: 1.0089027278531741.\n",
      "iter: 8, RMSE on training set: 0.9505018402256418, RMSE on testing set: 1.0028553438067689.\n",
      "iter: 9, RMSE on training set: 0.9457480243168717, RMSE on testing set: 1.0000817245894005.\n",
      "iter: 10, RMSE on training set: 0.9408817772335952, RMSE on testing set: 0.9972897858668043.\n",
      "iter: 11, RMSE on training set: 0.9376170602009121, RMSE on testing set: 0.9955637223937176.\n",
      "iter: 12, RMSE on training set: 0.934756096570172, RMSE on testing set: 0.9935848528012374.\n",
      "iter: 13, RMSE on training set: 0.9335757093852373, RMSE on testing set: 0.9932736273680095.\n",
      "iter: 14, RMSE on training set: 0.9320387230123137, RMSE on testing set: 0.9924095982941761.\n",
      "iter: 15, RMSE on training set: 0.9315619311384054, RMSE on testing set: 0.992193694310411.\n",
      "iter: 16, RMSE on training set: 0.9304544971657933, RMSE on testing set: 0.9912889089290299.\n",
      "iter: 17, RMSE on training set: 0.9304211212091604, RMSE on testing set: 0.9914774238795204.\n",
      "RMSE on test data: 0.9912889089290299.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# define parameters \n",
    "num_features = 25   # K in the lecture notes\n",
    "\n",
    "lambda_user = 0.08\n",
    "lambda_item = 0.08\n",
    "    \n",
    "gammas = np.logspace(-2,-1,num = 5)\n",
    "gamma_dec_step_sizes = np.linspace(1.1,1.3,5)\n",
    "\n",
    "\n",
    "num_epochs = 30     # number of full passes through the train set\n",
    "stop_criterion = 1e-4\n",
    "    \n",
    "seeds = np.array([988,1000])\n",
    "#seeds = np.array([988])\n",
    "\n",
    "rmse_te = np.zeros((len(seeds),len(gammas),len(gamma_dec_step_sizes)))\n",
    "\n",
    "for ind_seed, seed in enumerate(seeds):\n",
    "    for ind_gamma, gamma in enumerate(gammas):\n",
    "        for ind_gamma_dec_step_size, gamma_dec_step_size in enumerate(gamma_dec_step_sizes):\n",
    "            print(\"seed ({}/{}) = {}\".format(ind_seed+1, len(seeds), seed))\n",
    "            print(\"gamma ({}/{}) = {}\".format(ind_gamma+1, len(gammas), gamma))\n",
    "            print(\"stepsize decrement ({}/{}) = {}\".format(ind_gamma_dec_step_size+1, len(gamma_dec_step_sizes), gamma_dec_step_size))\n",
    "            \n",
    "            rmse_te[ind_seed,ind_gamma,ind_gamma_dec_step_size] = matrix_factorization_SGD_regularized(train, test, num_features, lambda_user, lambda_item, gamma, gamma_dec_step_size, num_epochs, seed, stop_criterion)\n",
    "\n",
    "np.save('../results_of_lengthy_computations/RMSE_test_tuning_gammas',rmse_te)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_test_tuning_lambdas = np.load('../results_of_lengthy_computations/RMSE_test_tuning_gammas.npy')\n",
    "gammas = np.logspace(-2,-1,num = 5)\n",
    "gamma_dec_step_sizes = np.linspace(1.1,1.3,5)\n",
    "plot_simple_heatmap(np.min(RMSE_test_tuning_lambdas, axis = 0), \"RMSE\", \"decrement\",np.around(gamma_dec_step_sizes,2), \"gamma\",np.around(gammas,2))\n",
    "plt.savefig('../plots/heatmap_tuning_gammas.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_user[user] * lambda_user\"\"\"\n",
    "\n",
    "    # update and return user feature.\n",
    "    user_features = np.zeros((item_features.shape[0],train.shape[1]))\n",
    "    \n",
    "    for n in range(train.shape[1]):\n",
    "        \n",
    "        item_features_n = np.zeros(item_features.shape)\n",
    "        item_features_n[:,nz_user_itemindices[n]] = item_features[:,nz_user_itemindices[n]]\n",
    "        user_features[:,n] = np.linalg.solve(np.dot(item_features_n,item_features.T)+lambda_user*nnz_items_per_user[n]*np.identity(user_features.shape[0]),np.dot(item_features,np.squeeze(np.asarray(train.getcol(n).todense()))))\n",
    "    \n",
    "    return user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    \"\"\"the best lambda is assumed to be nnz_items_per_item[item] * lambda_item\"\"\"\n",
    "\n",
    "    # update and return item feature.\n",
    "    item_features = np.zeros((user_features.shape[0],train.shape[0]))\n",
    "    \n",
    "    for d in range(train.shape[0]):\n",
    "        \n",
    "        user_features_d = np.zeros(user_features.shape)\n",
    "        user_features_d[:,nz_item_userindices[d]] = user_features[:,nz_item_userindices[d]]\n",
    "        item_features[:,d] = np.linalg.solve(np.dot(user_features_d,user_features.T)+lambda_item*nnz_users_per_item[d]*np.identity(user_features.shape[0]),np.dot(user_features,np.squeeze(np.asarray(train.getrow(d).todense()))))\n",
    "    \n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 1, RMSE on training set: 0.9519054032723246, RMSE on testing set: 1.017714471190868.\n",
      "iter: 2, RMSE on training set: 0.9315802604917478, RMSE on testing set: 1.003362815799362.\n",
      "iter: 3, RMSE on training set: 0.9100196143174027, RMSE on testing set: 0.9968938521418712.\n",
      "iter: 4, RMSE on training set: 0.8978135873998376, RMSE on testing set: 0.9935087567550255.\n",
      "iter: 5, RMSE on training set: 0.8908915580800574, RMSE on testing set: 0.9917070102761273.\n",
      "iter: 6, RMSE on training set: 0.8865317019111828, RMSE on testing set: 0.9905511255013821.\n",
      "iter: 7, RMSE on training set: 0.8836344304523723, RMSE on testing set: 0.9897784422755475.\n",
      "iter: 8, RMSE on training set: 0.8816238424159367, RMSE on testing set: 0.9892569669449173.\n",
      "iter: 9, RMSE on training set: 0.8801742015688895, RMSE on testing set: 0.9888997474217414.\n",
      "iter: 10, RMSE on training set: 0.8790928220247602, RMSE on testing set: 0.9886478056928241.\n",
      "iter: 11, RMSE on training set: 0.8782619377059661, RMSE on testing set: 0.9884624287961646.\n",
      "iter: 12, RMSE on training set: 0.8776075609080043, RMSE on testing set: 0.9883192402386162.\n",
      "iter: 13, RMSE on training set: 0.877081819201971, RMSE on testing set: 0.9882033595902621.\n",
      "iter: 14, RMSE on training set: 0.8766526582410334, RMSE on testing set: 0.9881058564714115.\n",
      "iter: 15, RMSE on training set: 0.8762977898107199, RMSE on testing set: 0.9880214079687479.\n",
      "iter: 16, RMSE on training set: 0.8760011300196024, RMSE on testing set: 0.9879468418787077.\n",
      "iter: 17, RMSE on training set: 0.8757506954999053, RMSE on testing set: 0.9878802513956939.\n",
      "iter: 18, RMSE on training set: 0.8755373396760372, RMSE on testing set: 0.9878204601453926.\n",
      "iter: 19, RMSE on training set: 0.8753539638995562, RMSE on testing set: 0.9877667018851771.\n",
      "iter: 20, RMSE on training set: 0.8751949972812412, RMSE on testing set: 0.9877184331340257.\n",
      "iter: 21, RMSE on training set: 0.8750560344208603, RMSE on testing set: 0.9876752276402443.\n",
      "iter: 22, RMSE on training set: 0.8749335722096998, RMSE on testing set: 0.9876367198654106.\n",
      "iter: 23, RMSE on training set: 0.8748248130406292, RMSE on testing set: 0.9876025765559421.\n",
      "iter: 24, RMSE on training set: 0.8747275147625057, RMSE on testing set: 0.9875724835059386.\n",
      "iter: 25, RMSE on training set: 0.8746398746290348, RMSE on testing set: 0.987546139957092.\n",
      "iter: 26, RMSE on training set: 0.8745604385635439, RMSE on testing set: 0.9875232564928758.\n",
      "RMSE on test data: 0.9875232564928758.\n"
     ]
    }
   ],
   "source": [
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 25   # K in the lecture notes\n",
    "    lambda_user = 0.08\n",
    "    lambda_item = 0.08\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [[0, 0]]\n",
    "    max_iter = 30\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # start you ALS-WR algorithm. \n",
    "    \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    \n",
    "    nz_user_itemindices = [nz_row[nz_col==n] for n in range(train.shape[1])]\n",
    "    nnz_items_per_user = np.array([len(nz_user_itemindice) for nz_user_itemindice in nz_user_itemindices])\n",
    "    nz_item_userindices = [nz_col[nz_row==d] for d in range(train.shape[0])]\n",
    "    nnz_users_per_item = np.array([len(nz_item_userindice) for nz_item_userindice in nz_item_userindices])\n",
    "    \n",
    "    rmse_tr = compute_error(train.data, user_features, item_features, train.nonzero())\n",
    "    rmse_te = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "    print(\"initial: RMSE on training set: {}, RMSE on testing set: {}.\".format(rmse_tr,rmse_te))\n",
    "    error_list.append([rmse_tr,rmse_te])\n",
    "    \n",
    "    it = 0\n",
    "    while (it < max_iter and not np.isclose(error_list[it][0],error_list[it+1][0],stop_criterion)):\n",
    "        it += 1\n",
    "        \n",
    "        user_features = update_user_feature(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "        \n",
    "        rmse_tr = compute_error(train.data, user_features, item_features, train.nonzero())\n",
    "        rmse_te = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "        print(\"iter: {}, RMSE on training set: {}, RMSE on testing set: {}.\".format(it, rmse_tr,rmse_te))\n",
    "        \n",
    "        error_list.append([rmse_tr,rmse_te])\n",
    "        \n",
    "    rmse = compute_error(test.data, user_features, item_features, test.nonzero())\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "       \n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best ridge parameters using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS(train, test, num_features, lambda_user, lambda_item, max_iter, seed):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # start you ALS-WR algorithm. \n",
    "    \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    \n",
    "    nz_user_itemindices = [nz_row[nz_col==n] for n in range(train.shape[1])]\n",
    "    nnz_items_per_user = np.array([len(nz_user_itemindice) for nz_user_itemindice in nz_user_itemindices])\n",
    "    nz_item_userindices = [nz_col[nz_row==d] for d in range(train.shape[0])]\n",
    "    nnz_users_per_item = np.array([len(nz_item_userindice) for nz_item_userindice in nz_item_userindices])\n",
    "    \n",
    "    rmse_tr = [compute_error(train.data, user_features, item_features, train.nonzero())]\n",
    "    rmse_te = [compute_error(test.data, user_features, item_features, test.nonzero())]\n",
    "    print(\"initial: RMSE on training set: {}, RMSE on testing set: {}.\".format(rmse_tr[0],rmse_te[0]))\n",
    "    \n",
    "\n",
    "    for it in range(max_iter):\n",
    "        \n",
    "        user_features = update_user_feature(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, lambda_item, nnz_users_per_item, nz_item_userindices)\n",
    "        \n",
    "        \n",
    "        \n",
    "        rmse_tr.append(compute_error(train.data, user_features, item_features, train.nonzero()))\n",
    "        rmse_te.append(compute_error(test.data, user_features, item_features, test.nonzero()))\n",
    "        print(\"iter: {}, RMSE on training set: {}, RMSE on testing set: {}.\".format(it, rmse_tr[-1],rmse_te[-1]))\n",
    "        \n",
    "        if np.isclose(rmse_tr[-1],rmse_tr[-2],stop_criterion) or rmse_tr[-1] > rmse_tr[0]:\n",
    "            break\n",
    "        \n",
    "    min_rmse_te = min(rmse_te)\n",
    "    print(\"RMSE on test data: {}.\".format(min_rmse_te))\n",
    "    \n",
    "    return min_rmse_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed (1/2) = 988\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.8900565026826133, RMSE on testing set: 1.1118608935236363.\n",
      "iter: 1, RMSE on training set: 0.8342085828124343, RMSE on testing set: 1.1225309771157455.\n",
      "iter: 2, RMSE on training set: 0.8133488350042751, RMSE on testing set: 1.1283590561540568.\n",
      "iter: 3, RMSE on training set: 0.8010823757779079, RMSE on testing set: 1.1313845872509731.\n",
      "iter: 4, RMSE on training set: 0.7935083863398478, RMSE on testing set: 1.1334478648264252.\n",
      "iter: 5, RMSE on training set: 0.7883764678435841, RMSE on testing set: 1.1348352328992795.\n",
      "iter: 6, RMSE on training set: 0.7846249722272582, RMSE on testing set: 1.1356865547654404.\n",
      "iter: 7, RMSE on training set: 0.7817472101536694, RMSE on testing set: 1.1361911874474637.\n",
      "iter: 8, RMSE on training set: 0.7794757455419334, RMSE on testing set: 1.136540853793994.\n",
      "iter: 9, RMSE on training set: 0.7776501007957896, RMSE on testing set: 1.1368635542781436.\n",
      "iter: 10, RMSE on training set: 0.776158515080935, RMSE on testing set: 1.1372234821479363.\n",
      "iter: 11, RMSE on training set: 0.7749177155516099, RMSE on testing set: 1.137637658219827.\n",
      "iter: 12, RMSE on training set: 0.7738666303189324, RMSE on testing set: 1.1380935605805904.\n",
      "iter: 13, RMSE on training set: 0.7729617286544718, RMSE on testing set: 1.1385690357036604.\n",
      "iter: 14, RMSE on training set: 0.7721722659057628, RMSE on testing set: 1.1390445422838176.\n",
      "RMSE on test data: 1.1118608935236363.\n",
      "seed (1/2) = 988\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (2/5) = 0.03162277660168379\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.8942610041908527, RMSE on testing set: 1.0891262551436254.\n",
      "iter: 1, RMSE on training set: 0.838650526632028, RMSE on testing set: 1.0945591691190268.\n",
      "iter: 2, RMSE on training set: 0.8180013447403088, RMSE on testing set: 1.0949599245768116.\n",
      "iter: 3, RMSE on training set: 0.8060522114041683, RMSE on testing set: 1.0941511001262954.\n",
      "iter: 4, RMSE on training set: 0.7987441683580186, RMSE on testing set: 1.0935896558096574.\n",
      "iter: 5, RMSE on training set: 0.7937860226145289, RMSE on testing set: 1.0930819178098006.\n",
      "iter: 6, RMSE on training set: 0.7901678852074003, RMSE on testing set: 1.0925867274962675.\n",
      "iter: 7, RMSE on training set: 0.7874178406864347, RMSE on testing set: 1.0921688503658926.\n",
      "iter: 8, RMSE on training set: 0.7852771648718551, RMSE on testing set: 1.0918818950394409.\n",
      "iter: 9, RMSE on training set: 0.7835798263935291, RMSE on testing set: 1.091727833002309.\n",
      "iter: 10, RMSE on training set: 0.782207695123328, RMSE on testing set: 1.0916782562431477.\n",
      "iter: 11, RMSE on training set: 0.7810753513069457, RMSE on testing set: 1.0917012182305563.\n",
      "iter: 12, RMSE on training set: 0.7801224725125825, RMSE on testing set: 1.0917727174345904.\n",
      "iter: 13, RMSE on training set: 0.7793072034027605, RMSE on testing set: 1.0918772369226437.\n",
      "iter: 14, RMSE on training set: 0.7786005772975735, RMSE on testing set: 1.0920044233440909.\n",
      "RMSE on test data: 1.0891262551436254.\n",
      "seed (1/2) = 988\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (3/5) = 0.1\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9157966177979611, RMSE on testing set: 1.057640441529872.\n",
      "iter: 1, RMSE on training set: 0.8557195834141194, RMSE on testing set: 1.0590208382198107.\n",
      "iter: 2, RMSE on training set: 0.8341605209058229, RMSE on testing set: 1.0554424143187744.\n",
      "iter: 3, RMSE on training set: 0.822153619820503, RMSE on testing set: 1.0524239890054552.\n",
      "iter: 4, RMSE on training set: 0.8148936266471241, RMSE on testing set: 1.0504984171158411.\n",
      "iter: 5, RMSE on training set: 0.8099973734271763, RMSE on testing set: 1.049088470374783.\n",
      "iter: 6, RMSE on training set: 0.8064729890367336, RMSE on testing set: 1.0480102839659917.\n",
      "iter: 7, RMSE on training set: 0.8038353236294302, RMSE on testing set: 1.0472003056512493.\n",
      "iter: 8, RMSE on training set: 0.8018032660911066, RMSE on testing set: 1.0466070169811987.\n",
      "iter: 9, RMSE on training set: 0.8001963361263352, RMSE on testing set: 1.0461786408132372.\n",
      "iter: 10, RMSE on training set: 0.7988939142088156, RMSE on testing set: 1.0458717445708756.\n",
      "iter: 11, RMSE on training set: 0.7978149527995598, RMSE on testing set: 1.0456524459538312.\n",
      "iter: 12, RMSE on training set: 0.7969048864850831, RMSE on testing set: 1.045493782811652.\n",
      "iter: 13, RMSE on training set: 0.7961265163639623, RMSE on testing set: 1.0453741858921395.\n",
      "iter: 14, RMSE on training set: 0.7954537254699032, RMSE on testing set: 1.0452771141382973.\n",
      "RMSE on test data: 1.0452771141382973.\n",
      "seed (1/2) = 988\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (4/5) = 0.31622776601683794\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9899342936158464, RMSE on testing set: 1.0683858106171311.\n",
      "iter: 1, RMSE on training set: 0.9199544145949708, RMSE on testing set: 1.0440292945113872.\n",
      "iter: 2, RMSE on training set: 0.8889017035152923, RMSE on testing set: 1.0335895689348866.\n",
      "iter: 3, RMSE on training set: 0.8727865351050258, RMSE on testing set: 1.0261632204847249.\n",
      "iter: 4, RMSE on training set: 0.8628405561791868, RMSE on testing set: 1.0211897861869934.\n",
      "iter: 5, RMSE on training set: 0.8560545317055626, RMSE on testing set: 1.0175897622846228.\n",
      "iter: 6, RMSE on training set: 0.8511588401327177, RMSE on testing set: 1.0148701136215779.\n",
      "iter: 7, RMSE on training set: 0.8474838020000369, RMSE on testing set: 1.0127727575989804.\n",
      "iter: 8, RMSE on training set: 0.8446372543316416, RMSE on testing set: 1.0111312784186615.\n",
      "iter: 9, RMSE on training set: 0.8423760082858428, RMSE on testing set: 1.0098253761525229.\n",
      "iter: 10, RMSE on training set: 0.840543060899043, RMSE on testing set: 1.0087664827882659.\n",
      "iter: 11, RMSE on training set: 0.8390334330289871, RMSE on testing set: 1.007890500454622.\n",
      "iter: 12, RMSE on training set: 0.8377743938151375, RMSE on testing set: 1.0071520762143158.\n",
      "iter: 13, RMSE on training set: 0.8367136681690971, RMSE on testing set: 1.0065196602562592.\n",
      "iter: 14, RMSE on training set: 0.835812347097776, RMSE on testing set: 1.0059714428310589.\n",
      "RMSE on test data: 1.0059714428310589.\n",
      "seed (1/2) = 988\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (5/5) = 1.0\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.2516422818982373, RMSE on testing set: 1.2867289920001055.\n",
      "iter: 1, RMSE on training set: 1.0965549131846066, RMSE on testing set: 1.1321981534658907.\n",
      "iter: 2, RMSE on training set: 1.028795483872254, RMSE on testing set: 1.0737722501630658.\n",
      "iter: 3, RMSE on training set: 0.9920860385310891, RMSE on testing set: 1.0442040286712784.\n",
      "iter: 4, RMSE on training set: 0.9704135541680704, RMSE on testing set: 1.0274497402728335.\n",
      "iter: 5, RMSE on training set: 0.9564198546823512, RMSE on testing set: 1.0170030031928223.\n",
      "iter: 6, RMSE on training set: 0.9468881587577503, RMSE on testing set: 1.0100365086835799.\n",
      "iter: 7, RMSE on training set: 0.9401371329295374, RMSE on testing set: 1.0051517869053044.\n",
      "iter: 8, RMSE on training set: 0.9352040815873144, RMSE on testing set: 1.0015946913704925.\n",
      "iter: 9, RMSE on training set: 0.9315023550983361, RMSE on testing set: 0.9989270274160145.\n",
      "iter: 10, RMSE on training set: 0.928658555117981, RMSE on testing set: 0.9968778896557351.\n",
      "iter: 11, RMSE on training set: 0.9264282057078318, RMSE on testing set: 0.9952717401467849.\n",
      "iter: 12, RMSE on training set: 0.9246475091333942, RMSE on testing set: 0.993990751212567.\n",
      "iter: 13, RMSE on training set: 0.9232040555581532, RMSE on testing set: 0.9929535941706653.\n",
      "iter: 14, RMSE on training set: 0.9220187337256083, RMSE on testing set: 0.9921028015265289.\n",
      "RMSE on test data: 0.9921028015265289.\n",
      "seed (1/2) = 988\n",
      "lambda_user (2/5) = 0.03162277660168379\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.8941823829379715, RMSE on testing set: 1.0849531269978558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1, RMSE on training set: 0.8372514314063599, RMSE on testing set: 1.0914120178638937.\n",
      "iter: 2, RMSE on training set: 0.8161801104047228, RMSE on testing set: 1.0928806956586785.\n",
      "iter: 3, RMSE on training set: 0.8045893077900117, RMSE on testing set: 1.092560265646262.\n",
      "iter: 4, RMSE on training set: 0.7975613191882547, RMSE on testing set: 1.0922531057556788.\n",
      "iter: 5, RMSE on training set: 0.7927980147165042, RMSE on testing set: 1.0918991798805249.\n",
      "iter: 6, RMSE on training set: 0.7893294474054723, RMSE on testing set: 1.0915153228824923.\n",
      "iter: 7, RMSE on training set: 0.7867006457153481, RMSE on testing set: 1.0911927827120902.\n",
      "iter: 8, RMSE on training set: 0.7846586062143702, RMSE on testing set: 1.090990492447238.\n",
      "iter: 9, RMSE on training set: 0.7830402010326099, RMSE on testing set: 1.0909052158622115.\n",
      "iter: 10, RMSE on training set: 0.7817302122482407, RMSE on testing set: 1.090905747137122.\n",
      "iter: 11, RMSE on training set: 0.7806462263116024, RMSE on testing set: 1.0909642425090904.\n",
      "iter: 12, RMSE on training set: 0.7797308308191405, RMSE on testing set: 1.0910643507448472.\n",
      "iter: 13, RMSE on training set: 0.7789450051953662, RMSE on testing set: 1.0911962889731552.\n",
      "iter: 14, RMSE on training set: 0.7782622468973751, RMSE on testing set: 1.0913513391271246.\n",
      "RMSE on test data: 1.0849531269978558.\n",
      "seed (1/2) = 988\n",
      "lambda_user (2/5) = 0.03162277660168379\n",
      "lambda_item (2/5) = 0.03162277660168379\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9027389839136191, RMSE on testing set: 1.0581294957762364.\n",
      "iter: 1, RMSE on training set: 0.8501663228241149, RMSE on testing set: 1.0543354636998246.\n",
      "iter: 2, RMSE on training set: 0.8296665832329213, RMSE on testing set: 1.051521020141272.\n",
      "iter: 3, RMSE on training set: 0.8184258867606815, RMSE on testing set: 1.0490629894793955.\n",
      "iter: 4, RMSE on training set: 0.8116153809726914, RMSE on testing set: 1.0474957883393667.\n",
      "iter: 5, RMSE on training set: 0.8070298714837847, RMSE on testing set: 1.0463242749885104.\n",
      "iter: 6, RMSE on training set: 0.8037529926582678, RMSE on testing set: 1.0454365290662884.\n",
      "iter: 7, RMSE on training set: 0.8013311354208723, RMSE on testing set: 1.0448004209274675.\n",
      "iter: 8, RMSE on training set: 0.7994945166946757, RMSE on testing set: 1.0443704920633092.\n",
      "iter: 9, RMSE on training set: 0.7980655699351202, RMSE on testing set: 1.0440946463177279.\n",
      "iter: 10, RMSE on training set: 0.7969242712927517, RMSE on testing set: 1.0439300011171728.\n",
      "iter: 11, RMSE on training set: 0.7959902909757756, RMSE on testing set: 1.0438440803616655.\n",
      "iter: 12, RMSE on training set: 0.795210241611786, RMSE on testing set: 1.0438112823480563.\n",
      "iter: 13, RMSE on training set: 0.7945482933671613, RMSE on testing set: 1.043811146408714.\n",
      "iter: 14, RMSE on training set: 0.7939797452702904, RMSE on testing set: 1.0438279706534022.\n",
      "RMSE on test data: 1.043811146408714.\n",
      "seed (1/2) = 988\n",
      "lambda_user (2/5) = 0.03162277660168379\n",
      "lambda_item (3/5) = 0.1\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9327840715962488, RMSE on testing set: 1.0326736816861095.\n",
      "iter: 1, RMSE on training set: 0.8904653142727356, RMSE on testing set: 1.0188296223291904.\n",
      "iter: 2, RMSE on training set: 0.8675370987282347, RMSE on testing set: 1.014205807939852.\n",
      "iter: 3, RMSE on training set: 0.8560577698612594, RMSE on testing set: 1.0108445933451096.\n",
      "iter: 4, RMSE on training set: 0.8493141262676587, RMSE on testing set: 1.0087702996632801.\n",
      "iter: 5, RMSE on training set: 0.8448835138895671, RMSE on testing set: 1.0073213607899048.\n",
      "iter: 6, RMSE on training set: 0.8417963142010803, RMSE on testing set: 1.0062730304931742.\n",
      "iter: 7, RMSE on training set: 0.8395541936833573, RMSE on testing set: 1.0055097758757843.\n",
      "iter: 8, RMSE on training set: 0.8378671936498272, RMSE on testing set: 1.0049485602810297.\n",
      "iter: 9, RMSE on training set: 0.8365569765808722, RMSE on testing set: 1.0045256292059523.\n",
      "iter: 10, RMSE on training set: 0.8355108369306192, RMSE on testing set: 1.0041941907411553.\n",
      "iter: 11, RMSE on training set: 0.8346561482897272, RMSE on testing set: 1.003922129523773.\n",
      "iter: 12, RMSE on training set: 0.8339450400839773, RMSE on testing set: 1.003688639550783.\n",
      "iter: 13, RMSE on training set: 0.8333450031713804, RMSE on testing set: 1.0034808701255489.\n",
      "iter: 14, RMSE on training set: 0.8328331232496645, RMSE on testing set: 1.0032912722547607.\n",
      "RMSE on test data: 1.0032912722547607.\n",
      "seed (1/2) = 988\n",
      "lambda_user (2/5) = 0.03162277660168379\n",
      "lambda_item (4/5) = 0.31622776601683794\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.006594930214934, RMSE on testing set: 1.0571167362935954.\n",
      "iter: 1, RMSE on training set: 0.9890957082223353, RMSE on testing set: 1.0308795051025204.\n",
      "iter: 2, RMSE on training set: 0.9699462621300812, RMSE on testing set: 1.0177339423507044.\n",
      "iter: 3, RMSE on training set: 0.955456542152329, RMSE on testing set: 1.0092472490305857.\n",
      "iter: 4, RMSE on training set: 0.9460178494541883, RMSE on testing set: 1.004083863853033.\n",
      "iter: 5, RMSE on training set: 0.9392606154787756, RMSE on testing set: 1.0005292207535454.\n",
      "iter: 6, RMSE on training set: 0.9343172486747463, RMSE on testing set: 0.9979501846787576.\n",
      "iter: 7, RMSE on training set: 0.9306407011095441, RMSE on testing set: 0.9960143547820169.\n",
      "iter: 8, RMSE on training set: 0.9278536175485109, RMSE on testing set: 0.9945214294480813.\n",
      "iter: 9, RMSE on training set: 0.9256980471875508, RMSE on testing set: 0.993344199485889.\n",
      "iter: 10, RMSE on training set: 0.9239981101719478, RMSE on testing set: 0.9923983868358027.\n",
      "iter: 11, RMSE on training set: 0.9226336101839631, RMSE on testing set: 0.9916263262243916.\n",
      "iter: 12, RMSE on training set: 0.9215215401768588, RMSE on testing set: 0.9909875217390443.\n",
      "iter: 13, RMSE on training set: 0.9206034786477848, RMSE on testing set: 0.9904528828204753.\n",
      "iter: 14, RMSE on training set: 0.9198373019644966, RMSE on testing set: 0.9900010782557565.\n",
      "RMSE on test data: 0.9900010782557565.\n",
      "seed (1/2) = 988\n",
      "lambda_user (2/5) = 0.03162277660168379\n",
      "lambda_item (5/5) = 1.0\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.2688171430309896, RMSE on testing set: 1.2919736502663546.\n",
      "iter: 1, RMSE on training set: 1.1331343678467416, RMSE on testing set: 1.144985930091053.\n",
      "iter: 2, RMSE on training set: 1.081045203944192, RMSE on testing set: 1.0918511224824923.\n",
      "iter: 3, RMSE on training set: 1.0542648641116843, RMSE on testing set: 1.0650911336638025.\n",
      "iter: 4, RMSE on training set: 1.0386072196965614, RMSE on testing set: 1.049616716902337.\n",
      "iter: 5, RMSE on training set: 1.0286456791631275, RMSE on testing set: 1.0398455329336171.\n",
      "iter: 6, RMSE on training set: 1.0219408079377184, RMSE on testing set: 1.0333001527884313.\n",
      "iter: 7, RMSE on training set: 1.017251474291826, RMSE on testing set: 1.0287311340847631.\n",
      "iter: 8, RMSE on training set: 1.013878859540966, RMSE on testing set: 1.0254431394138195.\n",
      "iter: 9, RMSE on training set: 1.0113987306198897, RMSE on testing set: 1.0230197412956783.\n",
      "iter: 10, RMSE on training set: 1.0095403954653182, RMSE on testing set: 1.0211982525107008.\n",
      "iter: 11, RMSE on training set: 1.008125342576306, RMSE on testing set: 1.0198066393559186.\n",
      "iter: 12, RMSE on training set: 1.0070328738573917, RMSE on testing set: 1.0187288644324621.\n",
      "iter: 13, RMSE on training set: 1.0061795695539288, RMSE on testing set: 1.0178846506258226.\n",
      "iter: 14, RMSE on training set: 1.0055065657599596, RMSE on testing set: 1.0172171775092207.\n",
      "RMSE on test data: 1.0172171775092207.\n",
      "seed (1/2) = 988\n",
      "lambda_user (3/5) = 0.1\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9072578659246899, RMSE on testing set: 1.0479890643128666.\n",
      "iter: 1, RMSE on training set: 0.8489426792995142, RMSE on testing set: 1.0526496587751035.\n",
      "iter: 2, RMSE on training set: 0.8287713411361443, RMSE on testing set: 1.0501331130884335.\n",
      "iter: 3, RMSE on training set: 0.8178087540701563, RMSE on testing set: 1.0478982935185088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 4, RMSE on training set: 0.8111121101104043, RMSE on testing set: 1.0464046780805087.\n",
      "iter: 5, RMSE on training set: 0.8065919532576101, RMSE on testing set: 1.0452783567651454.\n",
      "iter: 6, RMSE on training set: 0.8033733225362337, RMSE on testing set: 1.0444575575764936.\n",
      "iter: 7, RMSE on training set: 0.8010062750144732, RMSE on testing set: 1.0439095475542632.\n",
      "iter: 8, RMSE on training set: 0.7992169856183156, RMSE on testing set: 1.0435710578241628.\n",
      "iter: 9, RMSE on training set: 0.7978259451003644, RMSE on testing set: 1.043374983097363.\n",
      "iter: 10, RMSE on training set: 0.7967135898828998, RMSE on testing set: 1.0432713434558039.\n",
      "iter: 11, RMSE on training set: 0.7958009012021671, RMSE on testing set: 1.0432270711180978.\n",
      "iter: 12, RMSE on training set: 0.7950357774003795, RMSE on testing set: 1.043219953287221.\n",
      "iter: 13, RMSE on training set: 0.7943833986269679, RMSE on testing set: 1.0432345776720224.\n",
      "iter: 14, RMSE on training set: 0.7938198961465427, RMSE on testing set: 1.043260231575247.\n",
      "RMSE on test data: 1.043219953287221.\n",
      "seed (1/2) = 988\n",
      "lambda_user (3/5) = 0.1\n",
      "lambda_item (2/5) = 0.03162277660168379\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9306896531161487, RMSE on testing set: 1.0230971176516725.\n",
      "iter: 1, RMSE on training set: 0.8863505210745837, RMSE on testing set: 1.0141736559807069.\n",
      "iter: 2, RMSE on training set: 0.8636267645384461, RMSE on testing set: 1.0102587137521353.\n",
      "iter: 3, RMSE on training set: 0.8525354958500028, RMSE on testing set: 1.0072113769576982.\n",
      "iter: 4, RMSE on training set: 0.8460474194267439, RMSE on testing set: 1.005343363309123.\n",
      "iter: 5, RMSE on training set: 0.8418303101966551, RMSE on testing set: 1.0040849733125334.\n",
      "iter: 6, RMSE on training set: 0.8389458616418637, RMSE on testing set: 1.0032420004893388.\n",
      "iter: 7, RMSE on training set: 0.8369011482571301, RMSE on testing set: 1.0026933865595118.\n",
      "iter: 8, RMSE on training set: 0.8354033038649803, RMSE on testing set: 1.002341970287955.\n",
      "iter: 9, RMSE on training set: 0.8342709985290134, RMSE on testing set: 1.0021147306871279.\n",
      "iter: 10, RMSE on training set: 0.8333900309837636, RMSE on testing set: 1.0019618853024823.\n",
      "iter: 11, RMSE on training set: 0.8326873633930353, RMSE on testing set: 1.0018521340300965.\n",
      "iter: 12, RMSE on training set: 0.8321153356102794, RMSE on testing set: 1.0017668608699293.\n",
      "iter: 13, RMSE on training set: 0.8316420423752738, RMSE on testing set: 1.0016953819372356.\n",
      "iter: 14, RMSE on training set: 0.8312454499618879, RMSE on testing set: 1.0016317658205875.\n",
      "RMSE on test data: 1.0016317658205875.\n",
      "seed (1/2) = 988\n",
      "lambda_user (3/5) = 0.1\n",
      "lambda_item (3/5) = 0.1\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9674744809765213, RMSE on testing set: 1.015915661973171.\n",
      "iter: 1, RMSE on training set: 0.9622558945549753, RMSE on testing set: 1.0035975317357815.\n",
      "iter: 2, RMSE on training set: 0.949816771676981, RMSE on testing set: 0.9971028965807872.\n",
      "iter: 3, RMSE on training set: 0.9393512230459031, RMSE on testing set: 0.9927986787683547.\n",
      "iter: 4, RMSE on training set: 0.932926612967959, RMSE on testing set: 0.9907446143642207.\n",
      "iter: 5, RMSE on training set: 0.928405513150064, RMSE on testing set: 0.9895162549683493.\n",
      "iter: 6, RMSE on training set: 0.92519216655487, RMSE on testing set: 0.9887356668057978.\n",
      "iter: 7, RMSE on training set: 0.9229004477338789, RMSE on testing set: 0.9882328803744829.\n",
      "iter: 8, RMSE on training set: 0.9212410880797176, RMSE on testing set: 0.987902730241695.\n",
      "iter: 9, RMSE on training set: 0.9200148542952252, RMSE on testing set: 0.9876796926114874.\n",
      "iter: 10, RMSE on training set: 0.9190886459100732, RMSE on testing set: 0.9875235259803296.\n",
      "iter: 11, RMSE on training set: 0.9183741783833819, RMSE on testing set: 0.9874097294691386.\n",
      "iter: 12, RMSE on training set: 0.9178125288847973, RMSE on testing set: 0.9873234062070634.\n",
      "iter: 13, RMSE on training set: 0.9173636757816118, RMSE on testing set: 0.9872554433128479.\n",
      "iter: 14, RMSE on training set: 0.9169997589124166, RMSE on testing set: 0.9872002000573707.\n",
      "RMSE on test data: 0.9872002000573707.\n",
      "seed (1/2) = 988\n",
      "lambda_user (3/5) = 0.1\n",
      "lambda_item (4/5) = 0.31622776601683794\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0308605669726576, RMSE on testing set: 1.055460511188259.\n",
      "iter: 1, RMSE on training set: 1.0265145021444384, RMSE on testing set: 1.0390156715578998.\n",
      "iter: 2, RMSE on training set: 1.0221639364545616, RMSE on testing set: 1.03320408065496.\n",
      "iter: 3, RMSE on training set: 1.0182869388051388, RMSE on testing set: 1.0290965012829365.\n",
      "iter: 4, RMSE on training set: 1.015204949009344, RMSE on testing set: 1.026035810143147.\n",
      "iter: 5, RMSE on training set: 1.0127462933955798, RMSE on testing set: 1.0236745245357282.\n",
      "iter: 6, RMSE on training set: 1.0107514410058338, RMSE on testing set: 1.0218066650509243.\n",
      "iter: 7, RMSE on training set: 1.009118906286559, RMSE on testing set: 1.0203090297783228.\n",
      "iter: 8, RMSE on training set: 1.0077881178978585, RMSE on testing set: 1.0191055728045666.\n",
      "iter: 9, RMSE on training set: 1.006716863937579, RMSE on testing set: 1.0181436152612893.\n",
      "iter: 10, RMSE on training set: 1.0058669980565862, RMSE on testing set: 1.0173804255057404.\n",
      "iter: 11, RMSE on training set: 1.0052003494780468, RMSE on testing set: 1.0167782982415463.\n",
      "iter: 12, RMSE on training set: 1.0046804688352156, RMSE on testing set: 1.0163041822982257.\n",
      "iter: 13, RMSE on training set: 1.0042753074349042, RMSE on testing set: 1.0159303391832994.\n",
      "iter: 14, RMSE on training set: 1.0039585688972048, RMSE on testing set: 1.0156344665873143.\n",
      "RMSE on test data: 1.0156344665873143.\n",
      "seed (1/2) = 988\n",
      "lambda_user (3/5) = 0.1\n",
      "lambda_item (5/5) = 1.0\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.297534623620821, RMSE on testing set: 1.3110712806902693.\n",
      "iter: 1, RMSE on training set: 1.15750153400695, RMSE on testing set: 1.1667781643345385.\n",
      "iter: 2, RMSE on training set: 1.1047310849687497, RMSE on testing set: 1.1143290002359654.\n",
      "iter: 3, RMSE on training set: 1.078961712573389, RMSE on testing set: 1.0887720165306418.\n",
      "iter: 4, RMSE on training set: 1.064687301259098, RMSE on testing set: 1.07461861747553.\n",
      "iter: 5, RMSE on training set: 1.0561441499387365, RMSE on testing set: 1.066148046547848.\n",
      "iter: 6, RMSE on training set: 1.0507679636489984, RMSE on testing set: 1.0608173621692534.\n",
      "iter: 7, RMSE on training set: 1.0472692262746646, RMSE on testing set: 1.0573480882935846.\n",
      "iter: 8, RMSE on training set: 1.0449396516938148, RMSE on testing set: 1.0550380398994992.\n",
      "iter: 9, RMSE on training set: 1.0433639504464733, RMSE on testing set: 1.0534754951359748.\n",
      "iter: 10, RMSE on training set: 1.0422864854302334, RMSE on testing set: 1.0524069996521361.\n",
      "iter: 11, RMSE on training set: 1.0415441100220508, RMSE on testing set: 1.0516707904316354.\n",
      "iter: 12, RMSE on training set: 1.0410299017723934, RMSE on testing set: 1.0511608461952073.\n",
      "iter: 13, RMSE on training set: 1.0406724167879318, RMSE on testing set: 1.0508063220951687.\n",
      "iter: 14, RMSE on training set: 1.0404232455315563, RMSE on testing set: 1.050559212855704.\n",
      "RMSE on test data: 1.050559212855704.\n",
      "seed (1/2) = 988\n",
      "lambda_user (4/5) = 0.31622776601683794\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9484144689920232, RMSE on testing set: 1.0135577225585977.\n",
      "iter: 1, RMSE on training set: 0.889194412775643, RMSE on testing set: 1.0119248145341473.\n",
      "iter: 2, RMSE on training set: 0.8641662139241744, RMSE on testing set: 1.0091073596569515.\n",
      "iter: 3, RMSE on training set: 0.852803361831768, RMSE on testing set: 1.0061160483012574.\n",
      "iter: 4, RMSE on training set: 0.8461137111175293, RMSE on testing set: 1.0041999574724179.\n",
      "iter: 5, RMSE on training set: 0.8417758525005761, RMSE on testing set: 1.0029673416341371.\n",
      "iter: 6, RMSE on training set: 0.838827071473996, RMSE on testing set: 1.0022056496119183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 7, RMSE on training set: 0.8367445939181022, RMSE on testing set: 1.0017512851588835.\n",
      "iter: 8, RMSE on training set: 0.8352187477557332, RMSE on testing set: 1.0014827897312868.\n",
      "iter: 9, RMSE on training set: 0.8340625258810938, RMSE on testing set: 1.0013211054220676.\n",
      "iter: 10, RMSE on training set: 0.8331609605728901, RMSE on testing set: 1.0012198625155417.\n",
      "iter: 11, RMSE on training set: 0.8324413351239834, RMSE on testing set: 1.0011536113793167.\n",
      "iter: 12, RMSE on training set: 0.8318560417861505, RMSE on testing set: 1.001108682766672.\n",
      "iter: 13, RMSE on training set: 0.8313727794512211, RMSE on testing set: 1.001077531694877.\n",
      "iter: 14, RMSE on training set: 0.8309688660576576, RMSE on testing set: 1.001055708580811.\n",
      "RMSE on test data: 1.001055708580811.\n",
      "seed (1/2) = 988\n",
      "lambda_user (4/5) = 0.31622776601683794\n",
      "lambda_item (2/5) = 0.03162277660168379\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9751822233051665, RMSE on testing set: 1.0086171604610712.\n",
      "iter: 1, RMSE on training set: 0.9648384742423001, RMSE on testing set: 0.9992204565103384.\n",
      "iter: 2, RMSE on training set: 0.9498952672307489, RMSE on testing set: 0.9928266290709592.\n",
      "iter: 3, RMSE on training set: 0.9375848261545723, RMSE on testing set: 0.9884816898420018.\n",
      "iter: 4, RMSE on training set: 0.9302566727957572, RMSE on testing set: 0.9865624238826077.\n",
      "iter: 5, RMSE on training set: 0.9253253480985325, RMSE on testing set: 0.9855329013943392.\n",
      "iter: 6, RMSE on training set: 0.9219878877217823, RMSE on testing set: 0.9849899959916009.\n",
      "iter: 7, RMSE on training set: 0.9197410538450628, RMSE on testing set: 0.9847435502905955.\n",
      "iter: 8, RMSE on training set: 0.9182187470048816, RMSE on testing set: 0.9846716602344472.\n",
      "iter: 9, RMSE on training set: 0.9171734805327202, RMSE on testing set: 0.9846988510856346.\n",
      "iter: 10, RMSE on training set: 0.9164451733860781, RMSE on testing set: 0.9847803763782934.\n",
      "iter: 11, RMSE on training set: 0.9159314964543379, RMSE on testing set: 0.9848901075684496.\n",
      "iter: 12, RMSE on training set: 0.9155663062641518, RMSE on testing set: 0.9850127807663545.\n",
      "iter: 13, RMSE on training set: 0.915305787316406, RMSE on testing set: 0.9851394388316302.\n",
      "iter: 14, RMSE on training set: 0.9151200643756808, RMSE on testing set: 0.985264823964033.\n",
      "RMSE on test data: 0.9846716602344472.\n",
      "seed (1/2) = 988\n",
      "lambda_user (4/5) = 0.31622776601683794\n",
      "lambda_item (3/5) = 0.1\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9952497037773929, RMSE on testing set: 1.014085647061271.\n",
      "iter: 1, RMSE on training set: 0.9967240131535626, RMSE on testing set: 1.0085947010424905.\n",
      "iter: 2, RMSE on training set: 0.9985933548834993, RMSE on testing set: 1.009512876745502.\n",
      "iter: 3, RMSE on training set: 0.9996459033968236, RMSE on testing set: 1.0103895175946496.\n",
      "iter: 4, RMSE on training set: 1.0003983013131805, RMSE on testing set: 1.011136034820151.\n",
      "iter: 5, RMSE on training set: 1.0009528055344747, RMSE on testing set: 1.011744929485632.\n",
      "iter: 6, RMSE on training set: 1.001338728861698, RMSE on testing set: 1.012219619113828.\n",
      "iter: 7, RMSE on training set: 1.0015804122333274, RMSE on testing set: 1.0125737287606509.\n",
      "iter: 8, RMSE on training set: 1.0017121463239473, RMSE on testing set: 1.0128310309405313.\n",
      "iter: 9, RMSE on training set: 1.0017760614548898, RMSE on testing set: 1.0130212227715032.\n",
      "RMSE on test data: 1.0085947010424905.\n",
      "seed (1/2) = 988\n",
      "lambda_user (4/5) = 0.31622776601683794\n",
      "lambda_item (4/5) = 0.31622776601683794\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0518546585956818, RMSE on testing set: 1.0651157948697634.\n",
      "iter: 1, RMSE on training set: 1.045788246816632, RMSE on testing set: 1.0559402748344837.\n",
      "iter: 2, RMSE on training set: 1.0439364654327523, RMSE on testing set: 1.054045706021223.\n",
      "iter: 3, RMSE on training set: 1.042679715647122, RMSE on testing set: 1.0527972138405544.\n",
      "iter: 4, RMSE on training set: 1.0418158301519687, RMSE on testing set: 1.0519402981821582.\n",
      "iter: 5, RMSE on training set: 1.041218427024709, RMSE on testing set: 1.0513478173051045.\n",
      "iter: 6, RMSE on training set: 1.0408036209559788, RMSE on testing set: 1.0509364416635052.\n",
      "iter: 7, RMSE on training set: 1.0405147606226852, RMSE on testing set: 1.050649971158149.\n",
      "iter: 8, RMSE on training set: 1.0403131892134974, RMSE on testing set: 1.0504500669226242.\n",
      "iter: 9, RMSE on training set: 1.040172324250536, RMSE on testing set: 1.0503103666042062.\n",
      "iter: 10, RMSE on training set: 1.040073782167902, RMSE on testing set: 1.0502126389947046.\n",
      "RMSE on test data: 1.0502126389947046.\n",
      "seed (1/2) = 988\n",
      "lambda_user (4/5) = 0.31622776601683794\n",
      "lambda_item (5/5) = 1.0\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.3516020689621795, RMSE on testing set: 1.3610668585249237.\n",
      "RMSE on test data: 1.3052388688004901.\n",
      "seed (1/2) = 988\n",
      "lambda_user (5/5) = 1.0\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9864191878863193, RMSE on testing set: 1.0067937358353107.\n",
      "iter: 1, RMSE on training set: 0.9744720372140915, RMSE on testing set: 0.998878558779675.\n",
      "iter: 2, RMSE on training set: 0.956984211749881, RMSE on testing set: 0.9917942676863292.\n",
      "iter: 3, RMSE on training set: 0.9418083859154721, RMSE on testing set: 0.9870705102872892.\n",
      "iter: 4, RMSE on training set: 0.9323363042638343, RMSE on testing set: 0.9849903426522383.\n",
      "iter: 5, RMSE on training set: 0.9260224812475417, RMSE on testing set: 0.9839436693340168.\n",
      "iter: 6, RMSE on training set: 0.9218847977387429, RMSE on testing set: 0.9834696341092236.\n",
      "iter: 7, RMSE on training set: 0.9192131251710512, RMSE on testing set: 0.98331668571286.\n",
      "iter: 8, RMSE on training set: 0.9174824799267569, RMSE on testing set: 0.9833339300655903.\n",
      "iter: 9, RMSE on training set: 0.9163467809308286, RMSE on testing set: 0.983440117423584.\n",
      "iter: 10, RMSE on training set: 0.9155910729807963, RMSE on testing set: 0.983592646570954.\n",
      "iter: 11, RMSE on training set: 0.915083889696686, RMSE on testing set: 0.9837684542074078.\n",
      "iter: 12, RMSE on training set: 0.9147435834705855, RMSE on testing set: 0.9839543591931837.\n",
      "iter: 13, RMSE on training set: 0.9145178182860363, RMSE on testing set: 0.9841424272501134.\n",
      "iter: 14, RMSE on training set: 0.9143718545515721, RMSE on testing set: 0.9843277090227811.\n",
      "RMSE on test data: 0.98331668571286.\n",
      "seed (1/2) = 988\n",
      "lambda_user (5/5) = 1.0\n",
      "lambda_item (2/5) = 0.03162277660168379\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 0.9941658821703175, RMSE on testing set: 1.008067087137797.\n",
      "iter: 1, RMSE on training set: 0.992275937315928, RMSE on testing set: 1.0033637307957128.\n",
      "iter: 2, RMSE on training set: 0.9934703379173625, RMSE on testing set: 1.0041649392609275.\n",
      "iter: 3, RMSE on training set: 0.9945394035693933, RMSE on testing set: 1.005178742727851.\n",
      "iter: 4, RMSE on training set: 0.9955559992858445, RMSE on testing set: 1.006220589153372.\n",
      "iter: 5, RMSE on training set: 0.9964974277304824, RMSE on testing set: 1.0072225138901232.\n",
      "iter: 6, RMSE on training set: 0.9973291415718388, RMSE on testing set: 1.0081411221710337.\n",
      "iter: 7, RMSE on training set: 0.9980318754610047, RMSE on testing set: 1.0089532616665733.\n",
      "iter: 8, RMSE on training set: 0.998609095012049, RMSE on testing set: 1.009655615597991.\n",
      "iter: 9, RMSE on training set: 0.9990842715325459, RMSE on testing set: 1.0102608108016045.\n",
      "iter: 10, RMSE on training set: 0.9994898914935838, RMSE on testing set: 1.0107890553877448.\n",
      "iter: 11, RMSE on training set: 0.9998542686500135, RMSE on testing set: 1.0112589794990146.\n",
      "iter: 12, RMSE on training set: 1.0001939118649956, RMSE on testing set: 1.011682505286968.\n",
      "iter: 13, RMSE on training set: 1.000513870292841, RMSE on testing set: 1.0120649556383898.\n",
      "iter: 14, RMSE on training set: 1.0008124981230475, RMSE on testing set: 1.0124079018115852.\n",
      "RMSE on test data: 1.0033637307957128.\n",
      "seed (1/2) = 988\n",
      "lambda_user (5/5) = 1.0\n",
      "lambda_item (3/5) = 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0072873723081912, RMSE on testing set: 1.0190256179512769.\n",
      "iter: 1, RMSE on training set: 1.0098585915006129, RMSE on testing set: 1.020243622316415.\n",
      "iter: 2, RMSE on training set: 1.0161685532013376, RMSE on testing set: 1.0264920569616474.\n",
      "iter: 3, RMSE on training set: 1.0217605844333715, RMSE on testing set: 1.0320441514714755.\n",
      "iter: 4, RMSE on training set: 1.026353269378518, RMSE on testing set: 1.0366022448826517.\n",
      "iter: 5, RMSE on training set: 1.0299530135733173, RMSE on testing set: 1.0401738979144517.\n",
      "iter: 6, RMSE on training set: 1.032683820107225, RMSE on testing set: 1.0428829492259122.\n",
      "iter: 7, RMSE on training set: 1.0347080849581647, RMSE on testing set: 1.0448908847539846.\n",
      "iter: 8, RMSE on training set: 1.0361842335888019, RMSE on testing set: 1.046355031819927.\n",
      "iter: 9, RMSE on training set: 1.0372482838570063, RMSE on testing set: 1.0474103870442384.\n",
      "iter: 10, RMSE on training set: 1.038009036090094, RMSE on testing set: 1.0481649018148733.\n",
      "iter: 11, RMSE on training set: 1.038549817796902, RMSE on testing set: 1.0487012396207827.\n",
      "iter: 12, RMSE on training set: 1.0389326775413497, RMSE on testing set: 1.0490809483752939.\n",
      "iter: 13, RMSE on training set: 1.0392029609003872, RMSE on testing set: 1.0493490049258303.\n",
      "iter: 14, RMSE on training set: 1.0393933881496773, RMSE on testing set: 1.049537862145997.\n",
      "RMSE on test data: 1.0190256179512769.\n",
      "seed (1/2) = 988\n",
      "lambda_user (5/5) = 1.0\n",
      "lambda_item (4/5) = 0.31622776601683794\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.0939828273395076, RMSE on testing set: 1.104545347409929.\n",
      "iter: 1, RMSE on training set: 1.1118907398828333, RMSE on testing set: 1.1214677818322176.\n",
      "iter: 2, RMSE on training set: 1.1248200637373431, RMSE on testing set: 1.1342863168425883.\n",
      "iter: 3, RMSE on training set: 1.1318929201743546, RMSE on testing set: 1.1413019458564397.\n",
      "iter: 4, RMSE on training set: 1.1356071386816524, RMSE on testing set: 1.1449862800649468.\n",
      "iter: 5, RMSE on training set: 1.137521093550434, RMSE on testing set: 1.1468848723310814.\n",
      "iter: 6, RMSE on training set: 1.1384980159662599, RMSE on testing set: 1.1478539631518097.\n",
      "iter: 7, RMSE on training set: 1.1389942554178223, RMSE on testing set: 1.1483462270164642.\n",
      "iter: 8, RMSE on training set: 1.1392457103068128, RMSE on testing set: 1.1485956680562135.\n",
      "iter: 9, RMSE on training set: 1.139372970099455, RMSE on testing set: 1.1487219088225702.\n",
      "iter: 10, RMSE on training set: 1.1394373351919311, RMSE on testing set: 1.1487857585585752.\n",
      "RMSE on test data: 1.104545347409929.\n",
      "seed (1/2) = 988\n",
      "lambda_user (5/5) = 1.0\n",
      "lambda_item (5/5) = 1.0\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n",
      "iter: 0, RMSE on training set: 1.5166002315833798, RMSE on testing set: 1.5243389054079026.\n",
      "RMSE on test data: 1.3052388688004901.\n",
      "seed (2/2) = 1000\n",
      "lambda_user (1/5) = 0.01\n",
      "lambda_item (1/5) = 0.01\n",
      "initial: RMSE on training set: 1.3071287373574476, RMSE on testing set: 1.3052388688004901.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f7e30f1928e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lambda_item ({}/{}) = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind_lambda_item\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlambda_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mrmse_te\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind_seed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_lambda_user\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mind_lambda_item\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-4809d6c13ff5>\u001b[0m in \u001b[0;36mALS\u001b[1;34m(train, test, num_features, lambda_user, lambda_item, max_iter, seed)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0muser_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_user_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnnz_items_per_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnz_user_itemindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mitem_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_item_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnnz_users_per_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnz_item_userindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-e69d7e5420a9>\u001b[0m in \u001b[0;36mupdate_user_feature\u001b[1;34m(train, item_features, lambda_user, nnz_items_per_user, nz_user_itemindices)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mitem_features_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mitem_features_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnz_user_itemindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnz_user_itemindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0muser_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features_n\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlambda_user\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnnz_items_per_user\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mgetcol\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m    792\u001b[0m         col_selector = csc_matrix(([1], [[j], [0]]),\n\u001b[0;32m    793\u001b[0m                                   shape=(n, 1), dtype=self.dtype)\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcol_selector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgetrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# other * self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    510\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m            \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m            indptr, indices, data)\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# define parameters \n",
    "num_features = 25   # K in the lecture notes\n",
    "lambda_users = np.logspace(-2,0,num = 5)\n",
    "lambda_items = np.logspace(-2,0,num = 5)\n",
    "stop_criterion = 1e-4\n",
    "max_iter = 15\n",
    "    \n",
    "seeds = np.array([988])\n",
    "\n",
    "rmse_te = np.zeros((len(seeds),len(lambda_users),len(lambda_items)))\n",
    "\n",
    "for ind_seed, seed in enumerate(seeds):\n",
    "    for ind_lambda_user, lambda_user in enumerate(lambda_users):\n",
    "        for ind_lambda_item, lambda_item in enumerate(lambda_items):\n",
    "            print(\"seed ({}/{}) = {}\".format(ind_seed+1, len(seeds), seed))\n",
    "            print(\"lambda_user ({}/{}) = {}\".format(ind_lambda_user+1, len(lambda_users), lambda_user))\n",
    "            print(\"lambda_item ({}/{}) = {}\".format(ind_lambda_item+1, len(lambda_items), lambda_item))\n",
    "            \n",
    "            rmse_te[ind_seed,ind_lambda_user,ind_lambda_item] = ALS(train, test, num_features, lambda_user, lambda_item, max_iter, seed)\n",
    "\n",
    "np.save('../results_of_lengthy_computations/RMSE_test_tuning_lambdas',rmse_te)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_test_tuning_lambdas = np.load('../results_of_lengthy_computations/RMSE_test_tuning_lambdas.npy')\n",
    "lambda_users = np.logspace(-2,0,num = 5)\n",
    "lambda_items = np.logspace(-2,0,num = 5)\n",
    "plot_simple_heatmap(RMSE_test_tuning_lambdas, \"RMSE\", \"lambda item\",np.around(lambda_items,2), \"lambda user\",np.around(lambda_users,2))\n",
    "plt.savefig('../plots/heatmap_tuning_lambdas.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kmean. surely not the most efficient method\n",
    "- matrix factorizations\n",
    "- neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../Datasets/sample_submission.csv'\n",
    "pred_submission =\n",
    "create_csv_submission(ids_test, pred_submission, OUTPUT_PATH)\n",
    "raise NotImplementedError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
